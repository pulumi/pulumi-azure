# coding=utf-8
# *** WARNING: this file was generated by the Pulumi Terraform Bridge (tfgen) Tool. ***
# *** Do not edit by hand unless you're certain you know what you are doing! ***

import warnings
import pulumi
import pulumi.runtime
from typing import Any, Mapping, Optional, Sequence, Union
from .. import _utilities, _tables
from . import outputs

__all__ = [
    'ServiceAccountIdentity',
    'ServiceAccountStorageAccount',
    'TransformOutput',
    'TransformOutputAudioAnalyzerPreset',
    'TransformOutputBuiltinPreset',
    'TransformOutputFaceDetectorPreset',
    'TransformOutputVideoAnalyzerPreset',
]

@pulumi.output_type
class ServiceAccountIdentity(dict):
    def __init__(__self__, *,
                 principal_id: Optional[str] = None,
                 tenant_id: Optional[str] = None,
                 type: Optional[str] = None):
        """
        :param str principal_id: The Principal ID associated with this Managed Service Identity.
        :param str tenant_id: The Tenant ID associated with this Managed Service Identity.
        :param str type: Specifies the type of Managed Service Identity that should be configured on this Media Services Account. Possible value is  `SystemAssigned`.
        """
        if principal_id is not None:
            pulumi.set(__self__, "principal_id", principal_id)
        if tenant_id is not None:
            pulumi.set(__self__, "tenant_id", tenant_id)
        if type is not None:
            pulumi.set(__self__, "type", type)

    @property
    @pulumi.getter(name="principalId")
    def principal_id(self) -> Optional[str]:
        """
        The Principal ID associated with this Managed Service Identity.
        """
        return pulumi.get(self, "principal_id")

    @property
    @pulumi.getter(name="tenantId")
    def tenant_id(self) -> Optional[str]:
        """
        The Tenant ID associated with this Managed Service Identity.
        """
        return pulumi.get(self, "tenant_id")

    @property
    @pulumi.getter
    def type(self) -> Optional[str]:
        """
        Specifies the type of Managed Service Identity that should be configured on this Media Services Account. Possible value is  `SystemAssigned`.
        """
        return pulumi.get(self, "type")

    def _translate_property(self, prop):
        return _tables.CAMEL_TO_SNAKE_CASE_TABLE.get(prop) or prop


@pulumi.output_type
class ServiceAccountStorageAccount(dict):
    def __init__(__self__, *,
                 id: str,
                 is_primary: Optional[bool] = None):
        """
        :param str id: Specifies the ID of the Storage Account that will be associated with the Media Services instance.
        :param bool is_primary: Specifies whether the storage account should be the primary account or not. Defaults to `false`.
        """
        pulumi.set(__self__, "id", id)
        if is_primary is not None:
            pulumi.set(__self__, "is_primary", is_primary)

    @property
    @pulumi.getter
    def id(self) -> str:
        """
        Specifies the ID of the Storage Account that will be associated with the Media Services instance.
        """
        return pulumi.get(self, "id")

    @property
    @pulumi.getter(name="isPrimary")
    def is_primary(self) -> Optional[bool]:
        """
        Specifies whether the storage account should be the primary account or not. Defaults to `false`.
        """
        return pulumi.get(self, "is_primary")

    def _translate_property(self, prop):
        return _tables.CAMEL_TO_SNAKE_CASE_TABLE.get(prop) or prop


@pulumi.output_type
class TransformOutput(dict):
    def __init__(__self__, *,
                 audio_analyzer_preset: Optional['outputs.TransformOutputAudioAnalyzerPreset'] = None,
                 builtin_preset: Optional['outputs.TransformOutputBuiltinPreset'] = None,
                 face_detector_preset: Optional['outputs.TransformOutputFaceDetectorPreset'] = None,
                 on_error_action: Optional[str] = None,
                 relative_priority: Optional[str] = None,
                 video_analyzer_preset: Optional['outputs.TransformOutputVideoAnalyzerPreset'] = None):
        """
        :param 'TransformOutputAudioAnalyzerPresetArgs' audio_analyzer_preset: A `audio_analyzer_preset` block as defined below.
        :param 'TransformOutputBuiltinPresetArgs' builtin_preset: A `builtin_preset` block as defined below.
        :param 'TransformOutputFaceDetectorPresetArgs' face_detector_preset: A `face_detector_preset` block as defined below.
        :param str on_error_action: A Transform can define more than one outputs. This property defines what the service should do when one output fails - either continue to produce other outputs, or, stop the other outputs. The overall Job state will not reflect failures of outputs that are specified with `ContinueJob`. Possibles value are `StopProcessingJob` or `ContinueJob`.
        :param str relative_priority: Sets the relative priority of the TransformOutputs within a Transform. This sets the priority that the service uses for processing Transform Outputs. Possibles value are `High`, `Normal` or `Low`.
        :param 'TransformOutputVideoAnalyzerPresetArgs' video_analyzer_preset: A `video_analyzer_preset` block as defined below.
        """
        if audio_analyzer_preset is not None:
            pulumi.set(__self__, "audio_analyzer_preset", audio_analyzer_preset)
        if builtin_preset is not None:
            pulumi.set(__self__, "builtin_preset", builtin_preset)
        if face_detector_preset is not None:
            pulumi.set(__self__, "face_detector_preset", face_detector_preset)
        if on_error_action is not None:
            pulumi.set(__self__, "on_error_action", on_error_action)
        if relative_priority is not None:
            pulumi.set(__self__, "relative_priority", relative_priority)
        if video_analyzer_preset is not None:
            pulumi.set(__self__, "video_analyzer_preset", video_analyzer_preset)

    @property
    @pulumi.getter(name="audioAnalyzerPreset")
    def audio_analyzer_preset(self) -> Optional['outputs.TransformOutputAudioAnalyzerPreset']:
        """
        A `audio_analyzer_preset` block as defined below.
        """
        return pulumi.get(self, "audio_analyzer_preset")

    @property
    @pulumi.getter(name="builtinPreset")
    def builtin_preset(self) -> Optional['outputs.TransformOutputBuiltinPreset']:
        """
        A `builtin_preset` block as defined below.
        """
        return pulumi.get(self, "builtin_preset")

    @property
    @pulumi.getter(name="faceDetectorPreset")
    def face_detector_preset(self) -> Optional['outputs.TransformOutputFaceDetectorPreset']:
        """
        A `face_detector_preset` block as defined below.
        """
        return pulumi.get(self, "face_detector_preset")

    @property
    @pulumi.getter(name="onErrorAction")
    def on_error_action(self) -> Optional[str]:
        """
        A Transform can define more than one outputs. This property defines what the service should do when one output fails - either continue to produce other outputs, or, stop the other outputs. The overall Job state will not reflect failures of outputs that are specified with `ContinueJob`. Possibles value are `StopProcessingJob` or `ContinueJob`.
        """
        return pulumi.get(self, "on_error_action")

    @property
    @pulumi.getter(name="relativePriority")
    def relative_priority(self) -> Optional[str]:
        """
        Sets the relative priority of the TransformOutputs within a Transform. This sets the priority that the service uses for processing Transform Outputs. Possibles value are `High`, `Normal` or `Low`.
        """
        return pulumi.get(self, "relative_priority")

    @property
    @pulumi.getter(name="videoAnalyzerPreset")
    def video_analyzer_preset(self) -> Optional['outputs.TransformOutputVideoAnalyzerPreset']:
        """
        A `video_analyzer_preset` block as defined below.
        """
        return pulumi.get(self, "video_analyzer_preset")

    def _translate_property(self, prop):
        return _tables.CAMEL_TO_SNAKE_CASE_TABLE.get(prop) or prop


@pulumi.output_type
class TransformOutputAudioAnalyzerPreset(dict):
    def __init__(__self__, *,
                 audio_analysis_mode: Optional[str] = None,
                 audio_language: Optional[str] = None):
        """
        :param str audio_analysis_mode: Possibles value are `Basic` or `Standard`. Determines the set of audio analysis operations to be performed.
        :param str audio_language: The language for the audio payload in the input using the BCP-47 format of 'language tag-region' (e.g: 'en-US'). If you know the language of your content, it is recommended that you specify it. The language must be specified explicitly for AudioAnalysisMode:Basic, since automatic language detection is not included in basic mode. If the language isn't specified, automatic language detection will choose the first language detected and process with the selected language for the duration of the file. It does not currently support dynamically switching between languages after the first language is detected. The automatic detection works best with audio recordings with clearly discernable speech. If automatic detection fails to find the language, transcription would fallback to 'en-US'." The list of supported languages is available here: https://go.microsoft.com/fwlink/?linkid=2109463.
        """
        if audio_analysis_mode is not None:
            pulumi.set(__self__, "audio_analysis_mode", audio_analysis_mode)
        if audio_language is not None:
            pulumi.set(__self__, "audio_language", audio_language)

    @property
    @pulumi.getter(name="audioAnalysisMode")
    def audio_analysis_mode(self) -> Optional[str]:
        """
        Possibles value are `Basic` or `Standard`. Determines the set of audio analysis operations to be performed.
        """
        return pulumi.get(self, "audio_analysis_mode")

    @property
    @pulumi.getter(name="audioLanguage")
    def audio_language(self) -> Optional[str]:
        """
        The language for the audio payload in the input using the BCP-47 format of 'language tag-region' (e.g: 'en-US'). If you know the language of your content, it is recommended that you specify it. The language must be specified explicitly for AudioAnalysisMode:Basic, since automatic language detection is not included in basic mode. If the language isn't specified, automatic language detection will choose the first language detected and process with the selected language for the duration of the file. It does not currently support dynamically switching between languages after the first language is detected. The automatic detection works best with audio recordings with clearly discernable speech. If automatic detection fails to find the language, transcription would fallback to 'en-US'." The list of supported languages is available here: https://go.microsoft.com/fwlink/?linkid=2109463.
        """
        return pulumi.get(self, "audio_language")

    def _translate_property(self, prop):
        return _tables.CAMEL_TO_SNAKE_CASE_TABLE.get(prop) or prop


@pulumi.output_type
class TransformOutputBuiltinPreset(dict):
    def __init__(__self__, *,
                 preset_name: Optional[str] = None):
        """
        :param str preset_name: The built-in preset to be used for encoding videos. The allowed values are `AACGoodQualityAudio`, `AdaptiveStreaming`,`ContentAwareEncoding`, `ContentAwareEncodingExperimental`,`CopyAllBitrateNonInterleaved`, `H264MultipleBitrate1080p`,`H264MultipleBitrate720p`, `H264MultipleBitrateSD`,`H264SingleBitrate1080p`, `H264SingleBitrate720p` and `H264SingleBitrateSD`.
        """
        if preset_name is not None:
            pulumi.set(__self__, "preset_name", preset_name)

    @property
    @pulumi.getter(name="presetName")
    def preset_name(self) -> Optional[str]:
        """
        The built-in preset to be used for encoding videos. The allowed values are `AACGoodQualityAudio`, `AdaptiveStreaming`,`ContentAwareEncoding`, `ContentAwareEncodingExperimental`,`CopyAllBitrateNonInterleaved`, `H264MultipleBitrate1080p`,`H264MultipleBitrate720p`, `H264MultipleBitrateSD`,`H264SingleBitrate1080p`, `H264SingleBitrate720p` and `H264SingleBitrateSD`.
        """
        return pulumi.get(self, "preset_name")

    def _translate_property(self, prop):
        return _tables.CAMEL_TO_SNAKE_CASE_TABLE.get(prop) or prop


@pulumi.output_type
class TransformOutputFaceDetectorPreset(dict):
    def __init__(__self__, *,
                 analysis_resolution: Optional[str] = None):
        """
        :param str analysis_resolution: Possibles value are `SourceResolution` or `StandardDefinition`. Specifies the maximum resolution at which your video is analyzed. The default behavior is `SourceResolution` which will keep the input video at its original resolution when analyzed. Using `StandardDefinition` will resize input videos to standard definition while preserving the appropriate aspect ratio. It will only resize if the video is of higher resolution. For example, a 1920x1080 input would be scaled to 640x360 before processing. Switching to `StandardDefinition` will reduce the time it takes to process high resolution video. It may also reduce the cost of using this component (see https://azure.microsoft.com/en-us/pricing/details/media-services/#analytics for details). However, faces that end up being too small in the resized video may not be detected.
        """
        if analysis_resolution is not None:
            pulumi.set(__self__, "analysis_resolution", analysis_resolution)

    @property
    @pulumi.getter(name="analysisResolution")
    def analysis_resolution(self) -> Optional[str]:
        """
        Possibles value are `SourceResolution` or `StandardDefinition`. Specifies the maximum resolution at which your video is analyzed. The default behavior is `SourceResolution` which will keep the input video at its original resolution when analyzed. Using `StandardDefinition` will resize input videos to standard definition while preserving the appropriate aspect ratio. It will only resize if the video is of higher resolution. For example, a 1920x1080 input would be scaled to 640x360 before processing. Switching to `StandardDefinition` will reduce the time it takes to process high resolution video. It may also reduce the cost of using this component (see https://azure.microsoft.com/en-us/pricing/details/media-services/#analytics for details). However, faces that end up being too small in the resized video may not be detected.
        """
        return pulumi.get(self, "analysis_resolution")

    def _translate_property(self, prop):
        return _tables.CAMEL_TO_SNAKE_CASE_TABLE.get(prop) or prop


@pulumi.output_type
class TransformOutputVideoAnalyzerPreset(dict):
    def __init__(__self__, *,
                 audio_analysis_mode: Optional[str] = None,
                 audio_language: Optional[str] = None,
                 insights_type: Optional[str] = None):
        """
        :param str audio_analysis_mode: Possibles value are `Basic` or `Standard`. Determines the set of audio analysis operations to be performed.
        :param str audio_language: The language for the audio payload in the input using the BCP-47 format of 'language tag-region' (e.g: 'en-US'). If you know the language of your content, it is recommended that you specify it. The language must be specified explicitly for AudioAnalysisMode:Basic, since automatic language detection is not included in basic mode. If the language isn't specified, automatic language detection will choose the first language detected and process with the selected language for the duration of the file. It does not currently support dynamically switching between languages after the first language is detected. The automatic detection works best with audio recordings with clearly discernable speech. If automatic detection fails to find the language, transcription would fallback to 'en-US'." The list of supported languages is available here: https://go.microsoft.com/fwlink/?linkid=2109463.
        :param str insights_type: Defines the type of insights that you want the service to generate. The allowed values are `AudioInsightsOnly`, `VideoInsightsOnly`, and `AllInsights`. If you set this to `AllInsights` and the input is audio only, then only audio insights are generated. Similarly if the input is video only, then only video insights are generated. It is recommended that you not use `AudioInsightsOnly` if you expect some of your inputs to be video only; or use `VideoInsightsOnly` if you expect some of your inputs to be audio only. Your Jobs in such conditions would error out.
        """
        if audio_analysis_mode is not None:
            pulumi.set(__self__, "audio_analysis_mode", audio_analysis_mode)
        if audio_language is not None:
            pulumi.set(__self__, "audio_language", audio_language)
        if insights_type is not None:
            pulumi.set(__self__, "insights_type", insights_type)

    @property
    @pulumi.getter(name="audioAnalysisMode")
    def audio_analysis_mode(self) -> Optional[str]:
        """
        Possibles value are `Basic` or `Standard`. Determines the set of audio analysis operations to be performed.
        """
        return pulumi.get(self, "audio_analysis_mode")

    @property
    @pulumi.getter(name="audioLanguage")
    def audio_language(self) -> Optional[str]:
        """
        The language for the audio payload in the input using the BCP-47 format of 'language tag-region' (e.g: 'en-US'). If you know the language of your content, it is recommended that you specify it. The language must be specified explicitly for AudioAnalysisMode:Basic, since automatic language detection is not included in basic mode. If the language isn't specified, automatic language detection will choose the first language detected and process with the selected language for the duration of the file. It does not currently support dynamically switching between languages after the first language is detected. The automatic detection works best with audio recordings with clearly discernable speech. If automatic detection fails to find the language, transcription would fallback to 'en-US'." The list of supported languages is available here: https://go.microsoft.com/fwlink/?linkid=2109463.
        """
        return pulumi.get(self, "audio_language")

    @property
    @pulumi.getter(name="insightsType")
    def insights_type(self) -> Optional[str]:
        """
        Defines the type of insights that you want the service to generate. The allowed values are `AudioInsightsOnly`, `VideoInsightsOnly`, and `AllInsights`. If you set this to `AllInsights` and the input is audio only, then only audio insights are generated. Similarly if the input is video only, then only video insights are generated. It is recommended that you not use `AudioInsightsOnly` if you expect some of your inputs to be video only; or use `VideoInsightsOnly` if you expect some of your inputs to be audio only. Your Jobs in such conditions would error out.
        """
        return pulumi.get(self, "insights_type")

    def _translate_property(self, prop):
        return _tables.CAMEL_TO_SNAKE_CASE_TABLE.get(prop) or prop


