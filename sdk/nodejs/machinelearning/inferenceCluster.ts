// *** WARNING: this file was generated by pulumi-language-nodejs. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

import * as pulumi from "@pulumi/pulumi";
import * as inputs from "../types/input";
import * as outputs from "../types/output";
import * as utilities from "../utilities";

/**
 * Manages a Machine Learning Inference Cluster.
 *
 * > **Note:** The Machine Learning Inference Cluster resource is used to attach an existing AKS cluster to the Machine Learning Workspace, it doesn't create the AKS cluster itself. Therefore it can only be created and deleted, not updated. Any change to the configuration will recreate the resource.
 *
 * ## Example Usage
 *
 * ```typescript
 * import * as pulumi from "@pulumi/pulumi";
 * import * as azure from "@pulumi/azure";
 *
 * const current = azure.core.getClientConfig({});
 * const example = new azure.core.ResourceGroup("example", {
 *     name: "example-rg",
 *     location: "west europe",
 *     tags: {
 *         stage: "example",
 *     },
 * });
 * const exampleInsights = new azure.appinsights.Insights("example", {
 *     name: "example-ai",
 *     location: example.location,
 *     resourceGroupName: example.name,
 *     applicationType: "web",
 * });
 * const exampleKeyVault = new azure.keyvault.KeyVault("example", {
 *     name: "example-kv",
 *     location: example.location,
 *     resourceGroupName: example.name,
 *     tenantId: current.then(current => current.tenantId),
 *     skuName: "standard",
 *     purgeProtectionEnabled: true,
 * });
 * const exampleAccount = new azure.storage.Account("example", {
 *     name: "examplesa",
 *     location: example.location,
 *     resourceGroupName: example.name,
 *     accountTier: "Standard",
 *     accountReplicationType: "LRS",
 * });
 * const exampleWorkspace = new azure.machinelearning.Workspace("example", {
 *     name: "example-mlw",
 *     location: example.location,
 *     resourceGroupName: example.name,
 *     applicationInsightsId: exampleInsights.id,
 *     keyVaultId: exampleKeyVault.id,
 *     storageAccountId: exampleAccount.id,
 *     identity: {
 *         type: "SystemAssigned",
 *     },
 * });
 * const exampleVirtualNetwork = new azure.network.VirtualNetwork("example", {
 *     name: "example-vnet",
 *     addressSpaces: ["10.1.0.0/16"],
 *     location: example.location,
 *     resourceGroupName: example.name,
 * });
 * const exampleSubnet = new azure.network.Subnet("example", {
 *     name: "example-subnet",
 *     resourceGroupName: example.name,
 *     virtualNetworkName: exampleVirtualNetwork.name,
 *     addressPrefixes: ["10.1.0.0/24"],
 * });
 * const exampleKubernetesCluster = new azure.containerservice.KubernetesCluster("example", {
 *     name: "example-aks",
 *     location: example.location,
 *     resourceGroupName: example.name,
 *     dnsPrefixPrivateCluster: "prefix",
 *     defaultNodePool: {
 *         name: "default",
 *         nodeCount: 3,
 *         vmSize: "Standard_D3_v2",
 *         vnetSubnetId: exampleSubnet.id,
 *     },
 *     identity: {
 *         type: "SystemAssigned",
 *     },
 * });
 * const exampleInferenceCluster = new azure.machinelearning.InferenceCluster("example", {
 *     name: "example",
 *     location: example.location,
 *     clusterPurpose: "FastProd",
 *     kubernetesClusterId: exampleKubernetesCluster.id,
 *     description: "This is an example cluster used with Terraform",
 *     machineLearningWorkspaceId: exampleWorkspace.id,
 *     tags: {
 *         stage: "example",
 *     },
 * });
 * ```
 *
 * ## API Providers
 *
 * <!-- This section is generated, changes will be overwritten -->
 * This resource uses the following Azure API Providers:
 *
 * * `Microsoft.ContainerService` - 2025-02-01
 *
 * * `Microsoft.MachineLearningServices` - 2025-06-01
 *
 * ## Import
 *
 * Machine Learning Inference Clusters can be imported using the `resource id`, e.g.
 *
 * ```sh
 * $ pulumi import azure:machinelearning/inferenceCluster:InferenceCluster example /subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/resGroup1/providers/Microsoft.MachineLearningServices/workspaces/workspace1/computes/cluster1
 * ```
 */
export class InferenceCluster extends pulumi.CustomResource {
    /**
     * Get an existing InferenceCluster resource's state with the given name, ID, and optional extra
     * properties used to qualify the lookup.
     *
     * @param name The _unique_ name of the resulting resource.
     * @param id The _unique_ provider ID of the resource to lookup.
     * @param state Any extra arguments used during the lookup.
     * @param opts Optional settings to control the behavior of the CustomResource.
     */
    public static get(name: string, id: pulumi.Input<pulumi.ID>, state?: InferenceClusterState, opts?: pulumi.CustomResourceOptions): InferenceCluster {
        return new InferenceCluster(name, <any>state, { ...opts, id: id });
    }

    /** @internal */
    public static readonly __pulumiType = 'azure:machinelearning/inferenceCluster:InferenceCluster';

    /**
     * Returns true if the given object is an instance of InferenceCluster.  This is designed to work even
     * when multiple copies of the Pulumi SDK have been loaded into the same process.
     */
    public static isInstance(obj: any): obj is InferenceCluster {
        if (obj === undefined || obj === null) {
            return false;
        }
        return obj['__pulumiType'] === InferenceCluster.__pulumiType;
    }

    /**
     * The purpose of the Inference Cluster. Options are `DevTest`, `DenseProd` and `FastProd`. If used for Development or Testing, use `DevTest` here. Default purpose is `FastProd`, which is recommended for production workloads. Changing this forces a new Machine Learning Inference Cluster to be created.
     *
     * > **Note:** When creating or attaching a cluster, if the cluster will be used for production (`clusterPurpose = "FastProd"`), then it must contain at least 12 virtual CPUs. The number of virtual CPUs can be calculated by multiplying the number of nodes in the cluster by the number of cores provided by the VM size selected. For example, if you use a VM size of "Standard_D3_v2", which has 4 virtual cores, then you should select 3 or greater as the number of nodes.
     */
    public readonly clusterPurpose!: pulumi.Output<string | undefined>;
    /**
     * The description of the Machine Learning Inference Cluster. Changing this forces a new Machine Learning Inference Cluster to be created.
     */
    public readonly description!: pulumi.Output<string | undefined>;
    /**
     * An `identity` block as defined below. Changing this forces a new Machine Learning Inference Cluster to be created.
     */
    public readonly identity!: pulumi.Output<outputs.machinelearning.InferenceClusterIdentity | undefined>;
    /**
     * The ID of the Kubernetes Cluster. Changing this forces a new Machine Learning Inference Cluster to be created.
     */
    public readonly kubernetesClusterId!: pulumi.Output<string>;
    /**
     * The Azure Region where the Machine Learning Inference Cluster should exist. Changing this forces a new Machine Learning Inference Cluster to be created.
     */
    public readonly location!: pulumi.Output<string>;
    /**
     * The ID of the Machine Learning Workspace. Changing this forces a new Machine Learning Inference Cluster to be created.
     */
    public readonly machineLearningWorkspaceId!: pulumi.Output<string>;
    /**
     * The name which should be used for this Machine Learning Inference Cluster. Changing this forces a new Machine Learning Inference Cluster to be created.
     */
    public readonly name!: pulumi.Output<string>;
    /**
     * A `ssl` block as defined below. Changing this forces a new Machine Learning Inference Cluster to be created.
     */
    public readonly ssl!: pulumi.Output<outputs.machinelearning.InferenceClusterSsl | undefined>;
    /**
     * A mapping of tags which should be assigned to the Machine Learning Inference Cluster. Changing this forces a new Machine Learning Inference Cluster to be created.
     */
    public readonly tags!: pulumi.Output<{[key: string]: string} | undefined>;

    /**
     * Create a InferenceCluster resource with the given unique name, arguments, and options.
     *
     * @param name The _unique_ name of the resource.
     * @param args The arguments to use to populate this resource's properties.
     * @param opts A bag of options that control this resource's behavior.
     */
    constructor(name: string, args: InferenceClusterArgs, opts?: pulumi.CustomResourceOptions)
    constructor(name: string, argsOrState?: InferenceClusterArgs | InferenceClusterState, opts?: pulumi.CustomResourceOptions) {
        let resourceInputs: pulumi.Inputs = {};
        opts = opts || {};
        if (opts.id) {
            const state = argsOrState as InferenceClusterState | undefined;
            resourceInputs["clusterPurpose"] = state ? state.clusterPurpose : undefined;
            resourceInputs["description"] = state ? state.description : undefined;
            resourceInputs["identity"] = state ? state.identity : undefined;
            resourceInputs["kubernetesClusterId"] = state ? state.kubernetesClusterId : undefined;
            resourceInputs["location"] = state ? state.location : undefined;
            resourceInputs["machineLearningWorkspaceId"] = state ? state.machineLearningWorkspaceId : undefined;
            resourceInputs["name"] = state ? state.name : undefined;
            resourceInputs["ssl"] = state ? state.ssl : undefined;
            resourceInputs["tags"] = state ? state.tags : undefined;
        } else {
            const args = argsOrState as InferenceClusterArgs | undefined;
            if ((!args || args.kubernetesClusterId === undefined) && !opts.urn) {
                throw new Error("Missing required property 'kubernetesClusterId'");
            }
            if ((!args || args.machineLearningWorkspaceId === undefined) && !opts.urn) {
                throw new Error("Missing required property 'machineLearningWorkspaceId'");
            }
            resourceInputs["clusterPurpose"] = args ? args.clusterPurpose : undefined;
            resourceInputs["description"] = args ? args.description : undefined;
            resourceInputs["identity"] = args ? args.identity : undefined;
            resourceInputs["kubernetesClusterId"] = args ? args.kubernetesClusterId : undefined;
            resourceInputs["location"] = args ? args.location : undefined;
            resourceInputs["machineLearningWorkspaceId"] = args ? args.machineLearningWorkspaceId : undefined;
            resourceInputs["name"] = args ? args.name : undefined;
            resourceInputs["ssl"] = args ? args.ssl : undefined;
            resourceInputs["tags"] = args ? args.tags : undefined;
        }
        opts = pulumi.mergeOptions(utilities.resourceOptsDefaults(), opts);
        super(InferenceCluster.__pulumiType, name, resourceInputs, opts);
    }
}

/**
 * Input properties used for looking up and filtering InferenceCluster resources.
 */
export interface InferenceClusterState {
    /**
     * The purpose of the Inference Cluster. Options are `DevTest`, `DenseProd` and `FastProd`. If used for Development or Testing, use `DevTest` here. Default purpose is `FastProd`, which is recommended for production workloads. Changing this forces a new Machine Learning Inference Cluster to be created.
     *
     * > **Note:** When creating or attaching a cluster, if the cluster will be used for production (`clusterPurpose = "FastProd"`), then it must contain at least 12 virtual CPUs. The number of virtual CPUs can be calculated by multiplying the number of nodes in the cluster by the number of cores provided by the VM size selected. For example, if you use a VM size of "Standard_D3_v2", which has 4 virtual cores, then you should select 3 or greater as the number of nodes.
     */
    clusterPurpose?: pulumi.Input<string>;
    /**
     * The description of the Machine Learning Inference Cluster. Changing this forces a new Machine Learning Inference Cluster to be created.
     */
    description?: pulumi.Input<string>;
    /**
     * An `identity` block as defined below. Changing this forces a new Machine Learning Inference Cluster to be created.
     */
    identity?: pulumi.Input<inputs.machinelearning.InferenceClusterIdentity>;
    /**
     * The ID of the Kubernetes Cluster. Changing this forces a new Machine Learning Inference Cluster to be created.
     */
    kubernetesClusterId?: pulumi.Input<string>;
    /**
     * The Azure Region where the Machine Learning Inference Cluster should exist. Changing this forces a new Machine Learning Inference Cluster to be created.
     */
    location?: pulumi.Input<string>;
    /**
     * The ID of the Machine Learning Workspace. Changing this forces a new Machine Learning Inference Cluster to be created.
     */
    machineLearningWorkspaceId?: pulumi.Input<string>;
    /**
     * The name which should be used for this Machine Learning Inference Cluster. Changing this forces a new Machine Learning Inference Cluster to be created.
     */
    name?: pulumi.Input<string>;
    /**
     * A `ssl` block as defined below. Changing this forces a new Machine Learning Inference Cluster to be created.
     */
    ssl?: pulumi.Input<inputs.machinelearning.InferenceClusterSsl>;
    /**
     * A mapping of tags which should be assigned to the Machine Learning Inference Cluster. Changing this forces a new Machine Learning Inference Cluster to be created.
     */
    tags?: pulumi.Input<{[key: string]: pulumi.Input<string>}>;
}

/**
 * The set of arguments for constructing a InferenceCluster resource.
 */
export interface InferenceClusterArgs {
    /**
     * The purpose of the Inference Cluster. Options are `DevTest`, `DenseProd` and `FastProd`. If used for Development or Testing, use `DevTest` here. Default purpose is `FastProd`, which is recommended for production workloads. Changing this forces a new Machine Learning Inference Cluster to be created.
     *
     * > **Note:** When creating or attaching a cluster, if the cluster will be used for production (`clusterPurpose = "FastProd"`), then it must contain at least 12 virtual CPUs. The number of virtual CPUs can be calculated by multiplying the number of nodes in the cluster by the number of cores provided by the VM size selected. For example, if you use a VM size of "Standard_D3_v2", which has 4 virtual cores, then you should select 3 or greater as the number of nodes.
     */
    clusterPurpose?: pulumi.Input<string>;
    /**
     * The description of the Machine Learning Inference Cluster. Changing this forces a new Machine Learning Inference Cluster to be created.
     */
    description?: pulumi.Input<string>;
    /**
     * An `identity` block as defined below. Changing this forces a new Machine Learning Inference Cluster to be created.
     */
    identity?: pulumi.Input<inputs.machinelearning.InferenceClusterIdentity>;
    /**
     * The ID of the Kubernetes Cluster. Changing this forces a new Machine Learning Inference Cluster to be created.
     */
    kubernetesClusterId: pulumi.Input<string>;
    /**
     * The Azure Region where the Machine Learning Inference Cluster should exist. Changing this forces a new Machine Learning Inference Cluster to be created.
     */
    location?: pulumi.Input<string>;
    /**
     * The ID of the Machine Learning Workspace. Changing this forces a new Machine Learning Inference Cluster to be created.
     */
    machineLearningWorkspaceId: pulumi.Input<string>;
    /**
     * The name which should be used for this Machine Learning Inference Cluster. Changing this forces a new Machine Learning Inference Cluster to be created.
     */
    name?: pulumi.Input<string>;
    /**
     * A `ssl` block as defined below. Changing this forces a new Machine Learning Inference Cluster to be created.
     */
    ssl?: pulumi.Input<inputs.machinelearning.InferenceClusterSsl>;
    /**
     * A mapping of tags which should be assigned to the Machine Learning Inference Cluster. Changing this forces a new Machine Learning Inference Cluster to be created.
     */
    tags?: pulumi.Input<{[key: string]: pulumi.Input<string>}>;
}
