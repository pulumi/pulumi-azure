// *** WARNING: this file was generated by the Pulumi Terraform Bridge (tfgen) Tool. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

using System;
using System.Collections.Generic;
using System.Collections.Immutable;
using System.Threading.Tasks;
using Pulumi.Serialization;

namespace Pulumi.Azure.Synapse
{
    /// <summary>
    /// Manages a Synapse Spark Pool.
    /// 
    /// ## Import
    /// 
    /// Synapse Spark Pool can be imported using the `resource id`, e.g.
    /// 
    /// ```sh
    ///  $ pulumi import azure:synapse/sparkPool:SparkPool example /subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/group1/providers/Microsoft.Synapse/workspaces/workspace1/bigDataPools/sparkPool1
    /// ```
    /// </summary>
    [AzureResourceType("azure:synapse/sparkPool:SparkPool")]
    public partial class SparkPool : global::Pulumi.CustomResource
    {
        /// <summary>
        /// An `auto_pause` block as defined below.
        /// </summary>
        [Output("autoPause")]
        public Output<Outputs.SparkPoolAutoPause?> AutoPause { get; private set; } = null!;

        /// <summary>
        /// An `auto_scale` block as defined below. Exactly one of `node_count` or `auto_scale` must be specified.
        /// </summary>
        [Output("autoScale")]
        public Output<Outputs.SparkPoolAutoScale?> AutoScale { get; private set; } = null!;

        /// <summary>
        /// The cache size in the Spark Pool.
        /// </summary>
        [Output("cacheSize")]
        public Output<int?> CacheSize { get; private set; } = null!;

        /// <summary>
        /// Indicates whether compute isolation is enabled or not. Defaults to `false`.
        /// </summary>
        [Output("computeIsolationEnabled")]
        public Output<bool?> ComputeIsolationEnabled { get; private set; } = null!;

        /// <summary>
        /// Indicates whether Dynamic Executor Allocation is enabled or not. Defaults to `false`.
        /// </summary>
        [Output("dynamicExecutorAllocationEnabled")]
        public Output<bool?> DynamicExecutorAllocationEnabled { get; private set; } = null!;

        /// <summary>
        /// A `library_requirement` block as defined below.
        /// </summary>
        [Output("libraryRequirement")]
        public Output<Outputs.SparkPoolLibraryRequirement?> LibraryRequirement { get; private set; } = null!;

        /// <summary>
        /// The maximum number of executors allocated only when `dynamic_executor_allocation_enabled` set to `true`.
        /// </summary>
        [Output("maxExecutors")]
        public Output<int?> MaxExecutors { get; private set; } = null!;

        /// <summary>
        /// The minimum number of executors allocated only when `dynamic_executor_allocation_enabled` set to `true`.
        /// </summary>
        [Output("minExecutors")]
        public Output<int?> MinExecutors { get; private set; } = null!;

        /// <summary>
        /// The name which should be used for this Synapse Spark Pool. Changing this forces a new Synapse Spark Pool to be created.
        /// </summary>
        [Output("name")]
        public Output<string> Name { get; private set; } = null!;

        /// <summary>
        /// The number of nodes in the Spark Pool. Exactly one of `node_count` or `auto_scale` must be specified.
        /// </summary>
        [Output("nodeCount")]
        public Output<int?> NodeCount { get; private set; } = null!;

        /// <summary>
        /// The level of node in the Spark Pool. Possible values are `Small`, `Medium`, `Large`, `None`, `XLarge`, `XXLarge` and `XXXLarge`.
        /// </summary>
        [Output("nodeSize")]
        public Output<string> NodeSize { get; private set; } = null!;

        /// <summary>
        /// The kind of nodes that the Spark Pool provides. Possible values are `HardwareAcceleratedFPGA`, `HardwareAcceleratedGPU`, `MemoryOptimized`, and `None`.
        /// </summary>
        [Output("nodeSizeFamily")]
        public Output<string> NodeSizeFamily { get; private set; } = null!;

        /// <summary>
        /// Indicates whether session level packages are enabled or not. Defaults to `false`.
        /// </summary>
        [Output("sessionLevelPackagesEnabled")]
        public Output<bool?> SessionLevelPackagesEnabled { get; private set; } = null!;

        /// <summary>
        /// A `spark_config` block as defined below.
        /// </summary>
        [Output("sparkConfig")]
        public Output<Outputs.SparkPoolSparkConfig?> SparkConfig { get; private set; } = null!;

        /// <summary>
        /// The Spark events folder. Defaults to `/events`.
        /// </summary>
        [Output("sparkEventsFolder")]
        public Output<string?> SparkEventsFolder { get; private set; } = null!;

        /// <summary>
        /// The default folder where Spark logs will be written. Defaults to `/logs`.
        /// </summary>
        [Output("sparkLogFolder")]
        public Output<string?> SparkLogFolder { get; private set; } = null!;

        /// <summary>
        /// The Apache Spark version. Possible values are `2.4` , `3.1` , `3.2` and `3.3`. Defaults to `2.4`.
        /// </summary>
        [Output("sparkVersion")]
        public Output<string?> SparkVersion { get; private set; } = null!;

        /// <summary>
        /// The ID of the Synapse Workspace where the Synapse Spark Pool should exist. Changing this forces a new Synapse Spark Pool to be created.
        /// </summary>
        [Output("synapseWorkspaceId")]
        public Output<string> SynapseWorkspaceId { get; private set; } = null!;

        /// <summary>
        /// A mapping of tags which should be assigned to the Synapse Spark Pool.
        /// </summary>
        [Output("tags")]
        public Output<ImmutableDictionary<string, string>?> Tags { get; private set; } = null!;


        /// <summary>
        /// Create a SparkPool resource with the given unique name, arguments, and options.
        /// </summary>
        ///
        /// <param name="name">The unique name of the resource</param>
        /// <param name="args">The arguments used to populate this resource's properties</param>
        /// <param name="options">A bag of options that control this resource's behavior</param>
        public SparkPool(string name, SparkPoolArgs args, CustomResourceOptions? options = null)
            : base("azure:synapse/sparkPool:SparkPool", name, args ?? new SparkPoolArgs(), MakeResourceOptions(options, ""))
        {
        }

        private SparkPool(string name, Input<string> id, SparkPoolState? state = null, CustomResourceOptions? options = null)
            : base("azure:synapse/sparkPool:SparkPool", name, state, MakeResourceOptions(options, id))
        {
        }

        private static CustomResourceOptions MakeResourceOptions(CustomResourceOptions? options, Input<string>? id)
        {
            var defaultOptions = new CustomResourceOptions
            {
                Version = Utilities.Version,
            };
            var merged = CustomResourceOptions.Merge(defaultOptions, options);
            // Override the ID if one was specified for consistency with other language SDKs.
            merged.Id = id ?? merged.Id;
            return merged;
        }
        /// <summary>
        /// Get an existing SparkPool resource's state with the given name, ID, and optional extra
        /// properties used to qualify the lookup.
        /// </summary>
        ///
        /// <param name="name">The unique name of the resulting resource.</param>
        /// <param name="id">The unique provider ID of the resource to lookup.</param>
        /// <param name="state">Any extra arguments used during the lookup.</param>
        /// <param name="options">A bag of options that control this resource's behavior</param>
        public static SparkPool Get(string name, Input<string> id, SparkPoolState? state = null, CustomResourceOptions? options = null)
        {
            return new SparkPool(name, id, state, options);
        }
    }

    public sealed class SparkPoolArgs : global::Pulumi.ResourceArgs
    {
        /// <summary>
        /// An `auto_pause` block as defined below.
        /// </summary>
        [Input("autoPause")]
        public Input<Inputs.SparkPoolAutoPauseArgs>? AutoPause { get; set; }

        /// <summary>
        /// An `auto_scale` block as defined below. Exactly one of `node_count` or `auto_scale` must be specified.
        /// </summary>
        [Input("autoScale")]
        public Input<Inputs.SparkPoolAutoScaleArgs>? AutoScale { get; set; }

        /// <summary>
        /// The cache size in the Spark Pool.
        /// </summary>
        [Input("cacheSize")]
        public Input<int>? CacheSize { get; set; }

        /// <summary>
        /// Indicates whether compute isolation is enabled or not. Defaults to `false`.
        /// </summary>
        [Input("computeIsolationEnabled")]
        public Input<bool>? ComputeIsolationEnabled { get; set; }

        /// <summary>
        /// Indicates whether Dynamic Executor Allocation is enabled or not. Defaults to `false`.
        /// </summary>
        [Input("dynamicExecutorAllocationEnabled")]
        public Input<bool>? DynamicExecutorAllocationEnabled { get; set; }

        /// <summary>
        /// A `library_requirement` block as defined below.
        /// </summary>
        [Input("libraryRequirement")]
        public Input<Inputs.SparkPoolLibraryRequirementArgs>? LibraryRequirement { get; set; }

        /// <summary>
        /// The maximum number of executors allocated only when `dynamic_executor_allocation_enabled` set to `true`.
        /// </summary>
        [Input("maxExecutors")]
        public Input<int>? MaxExecutors { get; set; }

        /// <summary>
        /// The minimum number of executors allocated only when `dynamic_executor_allocation_enabled` set to `true`.
        /// </summary>
        [Input("minExecutors")]
        public Input<int>? MinExecutors { get; set; }

        /// <summary>
        /// The name which should be used for this Synapse Spark Pool. Changing this forces a new Synapse Spark Pool to be created.
        /// </summary>
        [Input("name")]
        public Input<string>? Name { get; set; }

        /// <summary>
        /// The number of nodes in the Spark Pool. Exactly one of `node_count` or `auto_scale` must be specified.
        /// </summary>
        [Input("nodeCount")]
        public Input<int>? NodeCount { get; set; }

        /// <summary>
        /// The level of node in the Spark Pool. Possible values are `Small`, `Medium`, `Large`, `None`, `XLarge`, `XXLarge` and `XXXLarge`.
        /// </summary>
        [Input("nodeSize", required: true)]
        public Input<string> NodeSize { get; set; } = null!;

        /// <summary>
        /// The kind of nodes that the Spark Pool provides. Possible values are `HardwareAcceleratedFPGA`, `HardwareAcceleratedGPU`, `MemoryOptimized`, and `None`.
        /// </summary>
        [Input("nodeSizeFamily", required: true)]
        public Input<string> NodeSizeFamily { get; set; } = null!;

        /// <summary>
        /// Indicates whether session level packages are enabled or not. Defaults to `false`.
        /// </summary>
        [Input("sessionLevelPackagesEnabled")]
        public Input<bool>? SessionLevelPackagesEnabled { get; set; }

        /// <summary>
        /// A `spark_config` block as defined below.
        /// </summary>
        [Input("sparkConfig")]
        public Input<Inputs.SparkPoolSparkConfigArgs>? SparkConfig { get; set; }

        /// <summary>
        /// The Spark events folder. Defaults to `/events`.
        /// </summary>
        [Input("sparkEventsFolder")]
        public Input<string>? SparkEventsFolder { get; set; }

        /// <summary>
        /// The default folder where Spark logs will be written. Defaults to `/logs`.
        /// </summary>
        [Input("sparkLogFolder")]
        public Input<string>? SparkLogFolder { get; set; }

        /// <summary>
        /// The Apache Spark version. Possible values are `2.4` , `3.1` , `3.2` and `3.3`. Defaults to `2.4`.
        /// </summary>
        [Input("sparkVersion")]
        public Input<string>? SparkVersion { get; set; }

        /// <summary>
        /// The ID of the Synapse Workspace where the Synapse Spark Pool should exist. Changing this forces a new Synapse Spark Pool to be created.
        /// </summary>
        [Input("synapseWorkspaceId", required: true)]
        public Input<string> SynapseWorkspaceId { get; set; } = null!;

        [Input("tags")]
        private InputMap<string>? _tags;

        /// <summary>
        /// A mapping of tags which should be assigned to the Synapse Spark Pool.
        /// </summary>
        public InputMap<string> Tags
        {
            get => _tags ?? (_tags = new InputMap<string>());
            set => _tags = value;
        }

        public SparkPoolArgs()
        {
        }
        public static new SparkPoolArgs Empty => new SparkPoolArgs();
    }

    public sealed class SparkPoolState : global::Pulumi.ResourceArgs
    {
        /// <summary>
        /// An `auto_pause` block as defined below.
        /// </summary>
        [Input("autoPause")]
        public Input<Inputs.SparkPoolAutoPauseGetArgs>? AutoPause { get; set; }

        /// <summary>
        /// An `auto_scale` block as defined below. Exactly one of `node_count` or `auto_scale` must be specified.
        /// </summary>
        [Input("autoScale")]
        public Input<Inputs.SparkPoolAutoScaleGetArgs>? AutoScale { get; set; }

        /// <summary>
        /// The cache size in the Spark Pool.
        /// </summary>
        [Input("cacheSize")]
        public Input<int>? CacheSize { get; set; }

        /// <summary>
        /// Indicates whether compute isolation is enabled or not. Defaults to `false`.
        /// </summary>
        [Input("computeIsolationEnabled")]
        public Input<bool>? ComputeIsolationEnabled { get; set; }

        /// <summary>
        /// Indicates whether Dynamic Executor Allocation is enabled or not. Defaults to `false`.
        /// </summary>
        [Input("dynamicExecutorAllocationEnabled")]
        public Input<bool>? DynamicExecutorAllocationEnabled { get; set; }

        /// <summary>
        /// A `library_requirement` block as defined below.
        /// </summary>
        [Input("libraryRequirement")]
        public Input<Inputs.SparkPoolLibraryRequirementGetArgs>? LibraryRequirement { get; set; }

        /// <summary>
        /// The maximum number of executors allocated only when `dynamic_executor_allocation_enabled` set to `true`.
        /// </summary>
        [Input("maxExecutors")]
        public Input<int>? MaxExecutors { get; set; }

        /// <summary>
        /// The minimum number of executors allocated only when `dynamic_executor_allocation_enabled` set to `true`.
        /// </summary>
        [Input("minExecutors")]
        public Input<int>? MinExecutors { get; set; }

        /// <summary>
        /// The name which should be used for this Synapse Spark Pool. Changing this forces a new Synapse Spark Pool to be created.
        /// </summary>
        [Input("name")]
        public Input<string>? Name { get; set; }

        /// <summary>
        /// The number of nodes in the Spark Pool. Exactly one of `node_count` or `auto_scale` must be specified.
        /// </summary>
        [Input("nodeCount")]
        public Input<int>? NodeCount { get; set; }

        /// <summary>
        /// The level of node in the Spark Pool. Possible values are `Small`, `Medium`, `Large`, `None`, `XLarge`, `XXLarge` and `XXXLarge`.
        /// </summary>
        [Input("nodeSize")]
        public Input<string>? NodeSize { get; set; }

        /// <summary>
        /// The kind of nodes that the Spark Pool provides. Possible values are `HardwareAcceleratedFPGA`, `HardwareAcceleratedGPU`, `MemoryOptimized`, and `None`.
        /// </summary>
        [Input("nodeSizeFamily")]
        public Input<string>? NodeSizeFamily { get; set; }

        /// <summary>
        /// Indicates whether session level packages are enabled or not. Defaults to `false`.
        /// </summary>
        [Input("sessionLevelPackagesEnabled")]
        public Input<bool>? SessionLevelPackagesEnabled { get; set; }

        /// <summary>
        /// A `spark_config` block as defined below.
        /// </summary>
        [Input("sparkConfig")]
        public Input<Inputs.SparkPoolSparkConfigGetArgs>? SparkConfig { get; set; }

        /// <summary>
        /// The Spark events folder. Defaults to `/events`.
        /// </summary>
        [Input("sparkEventsFolder")]
        public Input<string>? SparkEventsFolder { get; set; }

        /// <summary>
        /// The default folder where Spark logs will be written. Defaults to `/logs`.
        /// </summary>
        [Input("sparkLogFolder")]
        public Input<string>? SparkLogFolder { get; set; }

        /// <summary>
        /// The Apache Spark version. Possible values are `2.4` , `3.1` , `3.2` and `3.3`. Defaults to `2.4`.
        /// </summary>
        [Input("sparkVersion")]
        public Input<string>? SparkVersion { get; set; }

        /// <summary>
        /// The ID of the Synapse Workspace where the Synapse Spark Pool should exist. Changing this forces a new Synapse Spark Pool to be created.
        /// </summary>
        [Input("synapseWorkspaceId")]
        public Input<string>? SynapseWorkspaceId { get; set; }

        [Input("tags")]
        private InputMap<string>? _tags;

        /// <summary>
        /// A mapping of tags which should be assigned to the Synapse Spark Pool.
        /// </summary>
        public InputMap<string> Tags
        {
            get => _tags ?? (_tags = new InputMap<string>());
            set => _tags = value;
        }

        public SparkPoolState()
        {
        }
        public static new SparkPoolState Empty => new SparkPoolState();
    }
}
