// *** WARNING: this file was generated by the Pulumi Terraform Bridge (tfgen) Tool. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

using System;
using System.Collections.Generic;
using System.Collections.Immutable;
using System.Threading.Tasks;
using Pulumi.Serialization;

namespace Pulumi.Azure.Synapse
{
    /// <summary>
    /// Manages a Synapse Spark Pool.
    /// 
    /// ## Example Usage
    /// 
    /// ```csharp
    /// using System.Collections.Generic;
    /// using System.Linq;
    /// using Pulumi;
    /// using Azure = Pulumi.Azure;
    /// 
    /// return await Deployment.RunAsync(() =&gt; 
    /// {
    ///     var example = new Azure.Core.ResourceGroup("example", new()
    ///     {
    ///         Name = "example-resources",
    ///         Location = "West Europe",
    ///     });
    /// 
    ///     var exampleAccount = new Azure.Storage.Account("example", new()
    ///     {
    ///         Name = "examplestorageacc",
    ///         ResourceGroupName = example.Name,
    ///         Location = example.Location,
    ///         AccountTier = "Standard",
    ///         AccountReplicationType = "LRS",
    ///         AccountKind = "StorageV2",
    ///         IsHnsEnabled = true,
    ///     });
    /// 
    ///     var exampleDataLakeGen2Filesystem = new Azure.Storage.DataLakeGen2Filesystem("example", new()
    ///     {
    ///         Name = "example",
    ///         StorageAccountId = exampleAccount.Id,
    ///     });
    /// 
    ///     var exampleWorkspace = new Azure.Synapse.Workspace("example", new()
    ///     {
    ///         Name = "example",
    ///         ResourceGroupName = example.Name,
    ///         Location = example.Location,
    ///         StorageDataLakeGen2FilesystemId = exampleDataLakeGen2Filesystem.Id,
    ///         SqlAdministratorLogin = "sqladminuser",
    ///         SqlAdministratorLoginPassword = "H@Sh1CoR3!",
    ///         Identity = new Azure.Synapse.Inputs.WorkspaceIdentityArgs
    ///         {
    ///             Type = "SystemAssigned",
    ///         },
    ///     });
    /// 
    ///     var exampleSparkPool = new Azure.Synapse.SparkPool("example", new()
    ///     {
    ///         Name = "example",
    ///         SynapseWorkspaceId = exampleWorkspace.Id,
    ///         NodeSizeFamily = "MemoryOptimized",
    ///         NodeSize = "Small",
    ///         CacheSize = 100,
    ///         AutoScale = new Azure.Synapse.Inputs.SparkPoolAutoScaleArgs
    ///         {
    ///             MaxNodeCount = 50,
    ///             MinNodeCount = 3,
    ///         },
    ///         AutoPause = new Azure.Synapse.Inputs.SparkPoolAutoPauseArgs
    ///         {
    ///             DelayInMinutes = 15,
    ///         },
    ///         LibraryRequirement = new Azure.Synapse.Inputs.SparkPoolLibraryRequirementArgs
    ///         {
    ///             Content = @"appnope==0.1.0
    /// beautifulsoup4==4.6.3
    /// ",
    ///             Filename = "requirements.txt",
    ///         },
    ///         SparkConfig = new Azure.Synapse.Inputs.SparkPoolSparkConfigArgs
    ///         {
    ///             Content = @"spark.shuffle.spill                true
    /// ",
    ///             Filename = "config.txt",
    ///         },
    ///         SparkVersion = "3.2",
    ///         Tags = 
    ///         {
    ///             { "ENV", "Production" },
    ///         },
    ///     });
    /// 
    /// });
    /// ```
    /// 
    /// ## Import
    /// 
    /// Synapse Spark Pool can be imported using the `resource id`, e.g.
    /// 
    /// ```sh
    /// $ pulumi import azure:synapse/sparkPool:SparkPool example /subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/group1/providers/Microsoft.Synapse/workspaces/workspace1/bigDataPools/sparkPool1
    /// ```
    /// </summary>
    [AzureResourceType("azure:synapse/sparkPool:SparkPool")]
    public partial class SparkPool : global::Pulumi.CustomResource
    {
        /// <summary>
        /// An `auto_pause` block as defined below.
        /// </summary>
        [Output("autoPause")]
        public Output<Outputs.SparkPoolAutoPause?> AutoPause { get; private set; } = null!;

        /// <summary>
        /// An `auto_scale` block as defined below. Exactly one of `node_count` or `auto_scale` must be specified.
        /// </summary>
        [Output("autoScale")]
        public Output<Outputs.SparkPoolAutoScale?> AutoScale { get; private set; } = null!;

        /// <summary>
        /// The cache size in the Spark Pool.
        /// </summary>
        [Output("cacheSize")]
        public Output<int?> CacheSize { get; private set; } = null!;

        /// <summary>
        /// Indicates whether compute isolation is enabled or not. Defaults to `false`.
        /// </summary>
        [Output("computeIsolationEnabled")]
        public Output<bool?> ComputeIsolationEnabled { get; private set; } = null!;

        [Output("dynamicExecutorAllocationEnabled")]
        public Output<bool?> DynamicExecutorAllocationEnabled { get; private set; } = null!;

        [Output("libraryRequirement")]
        public Output<Outputs.SparkPoolLibraryRequirement?> LibraryRequirement { get; private set; } = null!;

        [Output("maxExecutors")]
        public Output<int?> MaxExecutors { get; private set; } = null!;

        [Output("minExecutors")]
        public Output<int?> MinExecutors { get; private set; } = null!;

        /// <summary>
        /// The name which should be used for this Synapse Spark Pool. Changing this forces a new Synapse Spark Pool to be created.
        /// </summary>
        [Output("name")]
        public Output<string> Name { get; private set; } = null!;

        /// <summary>
        /// The number of nodes in the Spark Pool. Exactly one of `node_count` or `auto_scale` must be specified.
        /// </summary>
        [Output("nodeCount")]
        public Output<int> NodeCount { get; private set; } = null!;

        /// <summary>
        /// The level of node in the Spark Pool. Possible values are `Small`, `Medium`, `Large`, `None`, `XLarge`, `XXLarge` and `XXXLarge`.
        /// </summary>
        [Output("nodeSize")]
        public Output<string> NodeSize { get; private set; } = null!;

        /// <summary>
        /// The kind of nodes that the Spark Pool provides. Possible values are `HardwareAcceleratedFPGA`, `HardwareAcceleratedGPU`, `MemoryOptimized`, and `None`.
        /// </summary>
        [Output("nodeSizeFamily")]
        public Output<string> NodeSizeFamily { get; private set; } = null!;

        [Output("sessionLevelPackagesEnabled")]
        public Output<bool?> SessionLevelPackagesEnabled { get; private set; } = null!;

        [Output("sparkConfig")]
        public Output<Outputs.SparkPoolSparkConfig?> SparkConfig { get; private set; } = null!;

        [Output("sparkEventsFolder")]
        public Output<string?> SparkEventsFolder { get; private set; } = null!;

        [Output("sparkLogFolder")]
        public Output<string?> SparkLogFolder { get; private set; } = null!;

        /// <summary>
        /// The Apache Spark version. Possible values are `3.2`, `3.3`, and `3.4`.
        /// </summary>
        [Output("sparkVersion")]
        public Output<string> SparkVersion { get; private set; } = null!;

        /// <summary>
        /// The ID of the Synapse Workspace where the Synapse Spark Pool should exist. Changing this forces a new Synapse Spark Pool to be created.
        /// </summary>
        [Output("synapseWorkspaceId")]
        public Output<string> SynapseWorkspaceId { get; private set; } = null!;

        [Output("tags")]
        public Output<ImmutableDictionary<string, string>?> Tags { get; private set; } = null!;


        /// <summary>
        /// Create a SparkPool resource with the given unique name, arguments, and options.
        /// </summary>
        ///
        /// <param name="name">The unique name of the resource</param>
        /// <param name="args">The arguments used to populate this resource's properties</param>
        /// <param name="options">A bag of options that control this resource's behavior</param>
        public SparkPool(string name, SparkPoolArgs args, CustomResourceOptions? options = null)
            : base("azure:synapse/sparkPool:SparkPool", name, args ?? new SparkPoolArgs(), MakeResourceOptions(options, ""))
        {
        }

        private SparkPool(string name, Input<string> id, SparkPoolState? state = null, CustomResourceOptions? options = null)
            : base("azure:synapse/sparkPool:SparkPool", name, state, MakeResourceOptions(options, id))
        {
        }

        private static CustomResourceOptions MakeResourceOptions(CustomResourceOptions? options, Input<string>? id)
        {
            var defaultOptions = new CustomResourceOptions
            {
                Version = Utilities.Version,
            };
            var merged = CustomResourceOptions.Merge(defaultOptions, options);
            // Override the ID if one was specified for consistency with other language SDKs.
            merged.Id = id ?? merged.Id;
            return merged;
        }
        /// <summary>
        /// Get an existing SparkPool resource's state with the given name, ID, and optional extra
        /// properties used to qualify the lookup.
        /// </summary>
        ///
        /// <param name="name">The unique name of the resulting resource.</param>
        /// <param name="id">The unique provider ID of the resource to lookup.</param>
        /// <param name="state">Any extra arguments used during the lookup.</param>
        /// <param name="options">A bag of options that control this resource's behavior</param>
        public static SparkPool Get(string name, Input<string> id, SparkPoolState? state = null, CustomResourceOptions? options = null)
        {
            return new SparkPool(name, id, state, options);
        }
    }

    public sealed class SparkPoolArgs : global::Pulumi.ResourceArgs
    {
        /// <summary>
        /// An `auto_pause` block as defined below.
        /// </summary>
        [Input("autoPause")]
        public Input<Inputs.SparkPoolAutoPauseArgs>? AutoPause { get; set; }

        /// <summary>
        /// An `auto_scale` block as defined below. Exactly one of `node_count` or `auto_scale` must be specified.
        /// </summary>
        [Input("autoScale")]
        public Input<Inputs.SparkPoolAutoScaleArgs>? AutoScale { get; set; }

        /// <summary>
        /// The cache size in the Spark Pool.
        /// </summary>
        [Input("cacheSize")]
        public Input<int>? CacheSize { get; set; }

        /// <summary>
        /// Indicates whether compute isolation is enabled or not. Defaults to `false`.
        /// </summary>
        [Input("computeIsolationEnabled")]
        public Input<bool>? ComputeIsolationEnabled { get; set; }

        [Input("dynamicExecutorAllocationEnabled")]
        public Input<bool>? DynamicExecutorAllocationEnabled { get; set; }

        [Input("libraryRequirement")]
        public Input<Inputs.SparkPoolLibraryRequirementArgs>? LibraryRequirement { get; set; }

        [Input("maxExecutors")]
        public Input<int>? MaxExecutors { get; set; }

        [Input("minExecutors")]
        public Input<int>? MinExecutors { get; set; }

        /// <summary>
        /// The name which should be used for this Synapse Spark Pool. Changing this forces a new Synapse Spark Pool to be created.
        /// </summary>
        [Input("name")]
        public Input<string>? Name { get; set; }

        /// <summary>
        /// The number of nodes in the Spark Pool. Exactly one of `node_count` or `auto_scale` must be specified.
        /// </summary>
        [Input("nodeCount")]
        public Input<int>? NodeCount { get; set; }

        /// <summary>
        /// The level of node in the Spark Pool. Possible values are `Small`, `Medium`, `Large`, `None`, `XLarge`, `XXLarge` and `XXXLarge`.
        /// </summary>
        [Input("nodeSize", required: true)]
        public Input<string> NodeSize { get; set; } = null!;

        /// <summary>
        /// The kind of nodes that the Spark Pool provides. Possible values are `HardwareAcceleratedFPGA`, `HardwareAcceleratedGPU`, `MemoryOptimized`, and `None`.
        /// </summary>
        [Input("nodeSizeFamily", required: true)]
        public Input<string> NodeSizeFamily { get; set; } = null!;

        [Input("sessionLevelPackagesEnabled")]
        public Input<bool>? SessionLevelPackagesEnabled { get; set; }

        [Input("sparkConfig")]
        public Input<Inputs.SparkPoolSparkConfigArgs>? SparkConfig { get; set; }

        [Input("sparkEventsFolder")]
        public Input<string>? SparkEventsFolder { get; set; }

        [Input("sparkLogFolder")]
        public Input<string>? SparkLogFolder { get; set; }

        /// <summary>
        /// The Apache Spark version. Possible values are `3.2`, `3.3`, and `3.4`.
        /// </summary>
        [Input("sparkVersion", required: true)]
        public Input<string> SparkVersion { get; set; } = null!;

        /// <summary>
        /// The ID of the Synapse Workspace where the Synapse Spark Pool should exist. Changing this forces a new Synapse Spark Pool to be created.
        /// </summary>
        [Input("synapseWorkspaceId", required: true)]
        public Input<string> SynapseWorkspaceId { get; set; } = null!;

        [Input("tags")]
        private InputMap<string>? _tags;
        public InputMap<string> Tags
        {
            get => _tags ?? (_tags = new InputMap<string>());
            set => _tags = value;
        }

        public SparkPoolArgs()
        {
        }
        public static new SparkPoolArgs Empty => new SparkPoolArgs();
    }

    public sealed class SparkPoolState : global::Pulumi.ResourceArgs
    {
        /// <summary>
        /// An `auto_pause` block as defined below.
        /// </summary>
        [Input("autoPause")]
        public Input<Inputs.SparkPoolAutoPauseGetArgs>? AutoPause { get; set; }

        /// <summary>
        /// An `auto_scale` block as defined below. Exactly one of `node_count` or `auto_scale` must be specified.
        /// </summary>
        [Input("autoScale")]
        public Input<Inputs.SparkPoolAutoScaleGetArgs>? AutoScale { get; set; }

        /// <summary>
        /// The cache size in the Spark Pool.
        /// </summary>
        [Input("cacheSize")]
        public Input<int>? CacheSize { get; set; }

        /// <summary>
        /// Indicates whether compute isolation is enabled or not. Defaults to `false`.
        /// </summary>
        [Input("computeIsolationEnabled")]
        public Input<bool>? ComputeIsolationEnabled { get; set; }

        [Input("dynamicExecutorAllocationEnabled")]
        public Input<bool>? DynamicExecutorAllocationEnabled { get; set; }

        [Input("libraryRequirement")]
        public Input<Inputs.SparkPoolLibraryRequirementGetArgs>? LibraryRequirement { get; set; }

        [Input("maxExecutors")]
        public Input<int>? MaxExecutors { get; set; }

        [Input("minExecutors")]
        public Input<int>? MinExecutors { get; set; }

        /// <summary>
        /// The name which should be used for this Synapse Spark Pool. Changing this forces a new Synapse Spark Pool to be created.
        /// </summary>
        [Input("name")]
        public Input<string>? Name { get; set; }

        /// <summary>
        /// The number of nodes in the Spark Pool. Exactly one of `node_count` or `auto_scale` must be specified.
        /// </summary>
        [Input("nodeCount")]
        public Input<int>? NodeCount { get; set; }

        /// <summary>
        /// The level of node in the Spark Pool. Possible values are `Small`, `Medium`, `Large`, `None`, `XLarge`, `XXLarge` and `XXXLarge`.
        /// </summary>
        [Input("nodeSize")]
        public Input<string>? NodeSize { get; set; }

        /// <summary>
        /// The kind of nodes that the Spark Pool provides. Possible values are `HardwareAcceleratedFPGA`, `HardwareAcceleratedGPU`, `MemoryOptimized`, and `None`.
        /// </summary>
        [Input("nodeSizeFamily")]
        public Input<string>? NodeSizeFamily { get; set; }

        [Input("sessionLevelPackagesEnabled")]
        public Input<bool>? SessionLevelPackagesEnabled { get; set; }

        [Input("sparkConfig")]
        public Input<Inputs.SparkPoolSparkConfigGetArgs>? SparkConfig { get; set; }

        [Input("sparkEventsFolder")]
        public Input<string>? SparkEventsFolder { get; set; }

        [Input("sparkLogFolder")]
        public Input<string>? SparkLogFolder { get; set; }

        /// <summary>
        /// The Apache Spark version. Possible values are `3.2`, `3.3`, and `3.4`.
        /// </summary>
        [Input("sparkVersion")]
        public Input<string>? SparkVersion { get; set; }

        /// <summary>
        /// The ID of the Synapse Workspace where the Synapse Spark Pool should exist. Changing this forces a new Synapse Spark Pool to be created.
        /// </summary>
        [Input("synapseWorkspaceId")]
        public Input<string>? SynapseWorkspaceId { get; set; }

        [Input("tags")]
        private InputMap<string>? _tags;
        public InputMap<string> Tags
        {
            get => _tags ?? (_tags = new InputMap<string>());
            set => _tags = value;
        }

        public SparkPoolState()
        {
        }
        public static new SparkPoolState Empty => new SparkPoolState();
    }
}
