// *** WARNING: this file was generated by the Pulumi Terraform Bridge (tfgen) Tool. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

using System;
using System.Collections.Generic;
using System.Collections.Immutable;
using System.Threading.Tasks;
using Pulumi.Serialization;

namespace Pulumi.Azure.Media.Outputs
{

    [OutputType]
    public sealed class TransformOutputFaceDetectorPreset
    {
        /// <summary>
        /// Possible values are `SourceResolution` or `StandardDefinition`. Specifies the maximum resolution at which your video is analyzed. which will keep the input video at its original resolution when analyzed. Using `StandardDefinition` will resize input videos to standard definition while preserving the appropriate aspect ratio. It will only resize if the video is of higher resolution. For example, a 1920x1080 input would be scaled to 640x360 before processing. Switching to `StandardDefinition` will reduce the time it takes to process high resolution video. It may also reduce the cost of using this component (see &lt;https://azure.microsoft.com/en-us/pricing/details/media-services/#analytics&gt; for details). However, faces that end up being too small in the resized video may not be detected. Default to `SourceResolution`.
        /// </summary>
        public readonly string? AnalysisResolution;
        /// <summary>
        /// Specifies the type of blur to apply to faces in the output video. Possible values are `Black`, `Box`, `High`, `Low`,and `Med`.
        /// </summary>
        public readonly string? BlurType;
        /// <summary>
        /// Dictionary containing key value pairs for parameters not exposed in the preset itself.
        /// </summary>
        public readonly ImmutableDictionary<string, string>? ExperimentalOptions;
        /// <summary>
        /// This mode provides the ability to choose between the following settings: 1) `Analyze` - For detection only. This mode generates a metadata JSON file marking appearances of faces throughout the video. Where possible, appearances of the same person are assigned the same ID. 2) `Combined` - Additionally redacts(blurs) detected faces. 3) `Redact` - This enables a 2-pass process, allowing for selective redaction of a subset of detected faces. It takes in the metadata file from a prior analyze pass, along with the source video, and a user-selected subset of IDs that require redaction. Default to `Analyze`.
        /// </summary>
        public readonly string? FaceRedactorMode;

        [OutputConstructor]
        private TransformOutputFaceDetectorPreset(
            string? analysisResolution,

            string? blurType,

            ImmutableDictionary<string, string>? experimentalOptions,

            string? faceRedactorMode)
        {
            AnalysisResolution = analysisResolution;
            BlurType = blurType;
            ExperimentalOptions = experimentalOptions;
            FaceRedactorMode = faceRedactorMode;
        }
    }
}
