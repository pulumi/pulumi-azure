// *** WARNING: this file was generated by pulumi-language-dotnet. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

using System;
using System.Collections.Generic;
using System.Collections.Immutable;
using System.Threading.Tasks;
using Pulumi.Serialization;

namespace Pulumi.Azure.DataFactory.Inputs
{

    public sealed class LinkedServiceAzureDatabricksNewClusterConfigGetArgs : global::Pulumi.ResourceArgs
    {
        /// <summary>
        /// Spark version of a the cluster.
        /// </summary>
        [Input("clusterVersion", required: true)]
        public Input<string> ClusterVersion { get; set; } = null!;

        [Input("customTags")]
        private InputMap<string>? _customTags;

        /// <summary>
        /// Tags for the cluster resource.
        /// </summary>
        public InputMap<string> CustomTags
        {
            get => _customTags ?? (_customTags = new InputMap<string>());
            set => _customTags = value;
        }

        /// <summary>
        /// Driver node type for the cluster.
        /// </summary>
        [Input("driverNodeType")]
        public Input<string>? DriverNodeType { get; set; }

        [Input("initScripts")]
        private InputList<string>? _initScripts;

        /// <summary>
        /// User defined initialization scripts for the cluster.
        /// </summary>
        public InputList<string> InitScripts
        {
            get => _initScripts ?? (_initScripts = new InputList<string>());
            set => _initScripts = value;
        }

        /// <summary>
        /// Location to deliver Spark driver, worker, and event logs.
        /// </summary>
        [Input("logDestination")]
        public Input<string>? LogDestination { get; set; }

        /// <summary>
        /// Specifies the maximum number of worker nodes. It should be between 1 and 25000.
        /// </summary>
        [Input("maxNumberOfWorkers")]
        public Input<int>? MaxNumberOfWorkers { get; set; }

        /// <summary>
        /// Specifies the minimum number of worker nodes. It should be between 1 and 25000. It defaults to `1`.
        /// </summary>
        [Input("minNumberOfWorkers")]
        public Input<int>? MinNumberOfWorkers { get; set; }

        /// <summary>
        /// Node type for the new cluster.
        /// </summary>
        [Input("nodeType", required: true)]
        public Input<string> NodeType { get; set; } = null!;

        [Input("sparkConfig")]
        private InputMap<string>? _sparkConfig;

        /// <summary>
        /// User-specified Spark configuration variables key-value pairs.
        /// </summary>
        public InputMap<string> SparkConfig
        {
            get => _sparkConfig ?? (_sparkConfig = new InputMap<string>());
            set => _sparkConfig = value;
        }

        [Input("sparkEnvironmentVariables")]
        private InputMap<string>? _sparkEnvironmentVariables;

        /// <summary>
        /// User-specified Spark environment variables key-value pairs.
        /// </summary>
        public InputMap<string> SparkEnvironmentVariables
        {
            get => _sparkEnvironmentVariables ?? (_sparkEnvironmentVariables = new InputMap<string>());
            set => _sparkEnvironmentVariables = value;
        }

        public LinkedServiceAzureDatabricksNewClusterConfigGetArgs()
        {
        }
        public static new LinkedServiceAzureDatabricksNewClusterConfigGetArgs Empty => new LinkedServiceAzureDatabricksNewClusterConfigGetArgs();
    }
}
