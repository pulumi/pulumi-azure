// *** WARNING: this file was generated by pulumi-java-gen. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

package com.pulumi.azure.datafactory;

import com.pulumi.azure.Utilities;
import com.pulumi.azure.datafactory.LinkedServiceAzureDatabricksArgs;
import com.pulumi.azure.datafactory.inputs.LinkedServiceAzureDatabricksState;
import com.pulumi.azure.datafactory.outputs.LinkedServiceAzureDatabricksInstancePool;
import com.pulumi.azure.datafactory.outputs.LinkedServiceAzureDatabricksKeyVaultPassword;
import com.pulumi.azure.datafactory.outputs.LinkedServiceAzureDatabricksNewClusterConfig;
import com.pulumi.core.Output;
import com.pulumi.core.annotations.Export;
import com.pulumi.core.annotations.ResourceType;
import com.pulumi.core.internal.Codegen;
import java.lang.String;
import java.util.List;
import java.util.Map;
import java.util.Optional;
import javax.annotation.Nullable;

/**
 * Manages a Linked Service (connection) between Azure Databricks and Azure Data Factory.
 * 
 * ## Example Usage
 * ### With Managed Identity &amp; New Cluster
 * ```java
 * package generated_program;
 * 
 * import com.pulumi.Context;
 * import com.pulumi.Pulumi;
 * import com.pulumi.core.Output;
 * import com.pulumi.azure.core.ResourceGroup;
 * import com.pulumi.azure.core.ResourceGroupArgs;
 * import com.pulumi.azure.datafactory.Factory;
 * import com.pulumi.azure.datafactory.FactoryArgs;
 * import com.pulumi.azure.datafactory.inputs.FactoryIdentityArgs;
 * import com.pulumi.azure.databricks.Workspace;
 * import com.pulumi.azure.databricks.WorkspaceArgs;
 * import com.pulumi.azure.datafactory.LinkedServiceAzureDatabricks;
 * import com.pulumi.azure.datafactory.LinkedServiceAzureDatabricksArgs;
 * import com.pulumi.azure.datafactory.inputs.LinkedServiceAzureDatabricksNewClusterConfigArgs;
 * import java.util.List;
 * import java.util.ArrayList;
 * import java.util.Map;
 * import java.io.File;
 * import java.nio.file.Files;
 * import java.nio.file.Paths;
 * 
 * public class App {
 *     public static void main(String[] args) {
 *         Pulumi.run(App::stack);
 *     }
 * 
 *     public static void stack(Context ctx) {
 *         var exampleResourceGroup = new ResourceGroup(&#34;exampleResourceGroup&#34;, ResourceGroupArgs.builder()        
 *             .location(&#34;East US&#34;)
 *             .build());
 * 
 *         var exampleFactory = new Factory(&#34;exampleFactory&#34;, FactoryArgs.builder()        
 *             .location(exampleResourceGroup.location())
 *             .resourceGroupName(exampleResourceGroup.name())
 *             .identity(FactoryIdentityArgs.builder()
 *                 .type(&#34;SystemAssigned&#34;)
 *                 .build())
 *             .build());
 * 
 *         var exampleWorkspace = new Workspace(&#34;exampleWorkspace&#34;, WorkspaceArgs.builder()        
 *             .resourceGroupName(exampleResourceGroup.name())
 *             .location(exampleResourceGroup.location())
 *             .sku(&#34;standard&#34;)
 *             .build());
 * 
 *         var msiLinked = new LinkedServiceAzureDatabricks(&#34;msiLinked&#34;, LinkedServiceAzureDatabricksArgs.builder()        
 *             .dataFactoryId(exampleFactory.id())
 *             .description(&#34;ADB Linked Service via MSI&#34;)
 *             .adbDomain(exampleWorkspace.workspaceUrl().applyValue(workspaceUrl -&gt; String.format(&#34;https://%s&#34;, workspaceUrl)))
 *             .msiWorkSpaceResourceId(exampleWorkspace.id())
 *             .newClusterConfig(LinkedServiceAzureDatabricksNewClusterConfigArgs.builder()
 *                 .nodeType(&#34;Standard_NC12&#34;)
 *                 .clusterVersion(&#34;5.5.x-gpu-scala2.11&#34;)
 *                 .minNumberOfWorkers(1)
 *                 .maxNumberOfWorkers(5)
 *                 .driverNodeType(&#34;Standard_NC12&#34;)
 *                 .logDestination(&#34;dbfs:/logs&#34;)
 *                 .customTags(Map.ofEntries(
 *                     Map.entry(&#34;custom_tag1&#34;, &#34;sct_value_1&#34;),
 *                     Map.entry(&#34;custom_tag2&#34;, &#34;sct_value_2&#34;)
 *                 ))
 *                 .sparkConfig(Map.ofEntries(
 *                     Map.entry(&#34;config1&#34;, &#34;value1&#34;),
 *                     Map.entry(&#34;config2&#34;, &#34;value2&#34;)
 *                 ))
 *                 .sparkEnvironmentVariables(Map.ofEntries(
 *                     Map.entry(&#34;envVar1&#34;, &#34;value1&#34;),
 *                     Map.entry(&#34;envVar2&#34;, &#34;value2&#34;)
 *                 ))
 *                 .initScripts(                
 *                     &#34;init.sh&#34;,
 *                     &#34;init2.sh&#34;)
 *                 .build())
 *             .build());
 * 
 *     }
 * }
 * ```
 * ### With Access Token &amp; Existing Cluster
 * ```java
 * package generated_program;
 * 
 * import com.pulumi.Context;
 * import com.pulumi.Pulumi;
 * import com.pulumi.core.Output;
 * import com.pulumi.azure.core.ResourceGroup;
 * import com.pulumi.azure.core.ResourceGroupArgs;
 * import com.pulumi.azure.datafactory.Factory;
 * import com.pulumi.azure.datafactory.FactoryArgs;
 * import com.pulumi.azure.databricks.Workspace;
 * import com.pulumi.azure.databricks.WorkspaceArgs;
 * import com.pulumi.azure.datafactory.LinkedServiceAzureDatabricks;
 * import com.pulumi.azure.datafactory.LinkedServiceAzureDatabricksArgs;
 * import java.util.List;
 * import java.util.ArrayList;
 * import java.util.Map;
 * import java.io.File;
 * import java.nio.file.Files;
 * import java.nio.file.Paths;
 * 
 * public class App {
 *     public static void main(String[] args) {
 *         Pulumi.run(App::stack);
 *     }
 * 
 *     public static void stack(Context ctx) {
 *         var exampleResourceGroup = new ResourceGroup(&#34;exampleResourceGroup&#34;, ResourceGroupArgs.builder()        
 *             .location(&#34;East US&#34;)
 *             .build());
 * 
 *         var exampleFactory = new Factory(&#34;exampleFactory&#34;, FactoryArgs.builder()        
 *             .location(exampleResourceGroup.location())
 *             .resourceGroupName(exampleResourceGroup.name())
 *             .build());
 * 
 *         var exampleWorkspace = new Workspace(&#34;exampleWorkspace&#34;, WorkspaceArgs.builder()        
 *             .resourceGroupName(exampleResourceGroup.name())
 *             .location(exampleResourceGroup.location())
 *             .sku(&#34;standard&#34;)
 *             .build());
 * 
 *         var atLinked = new LinkedServiceAzureDatabricks(&#34;atLinked&#34;, LinkedServiceAzureDatabricksArgs.builder()        
 *             .dataFactoryId(exampleFactory.id())
 *             .description(&#34;ADB Linked Service via Access Token&#34;)
 *             .existingClusterId(&#34;0308-201146-sly615&#34;)
 *             .accessToken(&#34;SomeDatabricksAccessToken&#34;)
 *             .adbDomain(exampleWorkspace.workspaceUrl().applyValue(workspaceUrl -&gt; String.format(&#34;https://%s&#34;, workspaceUrl)))
 *             .build());
 * 
 *     }
 * }
 * ```
 * 
 * ## Import
 * 
 * Data Factory Linked Services can be imported using the `resource id`, e.g.
 * 
 * ```sh
 *  $ pulumi import azure:datafactory/linkedServiceAzureDatabricks:LinkedServiceAzureDatabricks example /subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/example/providers/Microsoft.DataFactory/factories/example/linkedservices/example
 * ```
 * 
 */
@ResourceType(type="azure:datafactory/linkedServiceAzureDatabricks:LinkedServiceAzureDatabricks")
public class LinkedServiceAzureDatabricks extends com.pulumi.resources.CustomResource {
    /**
     * Authenticate to ADB via an access token.
     * 
     */
    @Export(name="accessToken", refs={String.class}, tree="[0]")
    private Output</* @Nullable */ String> accessToken;

    /**
     * @return Authenticate to ADB via an access token.
     * 
     */
    public Output<Optional<String>> accessToken() {
        return Codegen.optional(this.accessToken);
    }
    /**
     * The domain URL of the databricks instance.
     * 
     */
    @Export(name="adbDomain", refs={String.class}, tree="[0]")
    private Output<String> adbDomain;

    /**
     * @return The domain URL of the databricks instance.
     * 
     */
    public Output<String> adbDomain() {
        return this.adbDomain;
    }
    /**
     * A map of additional properties to associate with the Data Factory Linked Service.
     * 
     */
    @Export(name="additionalProperties", refs={Map.class,String.class}, tree="[0,1,1]")
    private Output</* @Nullable */ Map<String,String>> additionalProperties;

    /**
     * @return A map of additional properties to associate with the Data Factory Linked Service.
     * 
     */
    public Output<Optional<Map<String,String>>> additionalProperties() {
        return Codegen.optional(this.additionalProperties);
    }
    /**
     * List of tags that can be used for describing the Data Factory Linked Service.
     * 
     */
    @Export(name="annotations", refs={List.class,String.class}, tree="[0,1]")
    private Output</* @Nullable */ List<String>> annotations;

    /**
     * @return List of tags that can be used for describing the Data Factory Linked Service.
     * 
     */
    public Output<Optional<List<String>>> annotations() {
        return Codegen.optional(this.annotations);
    }
    /**
     * The Data Factory ID in which to associate the Linked Service with. Changing this forces a new resource.
     * 
     */
    @Export(name="dataFactoryId", refs={String.class}, tree="[0]")
    private Output<String> dataFactoryId;

    /**
     * @return The Data Factory ID in which to associate the Linked Service with. Changing this forces a new resource.
     * 
     */
    public Output<String> dataFactoryId() {
        return this.dataFactoryId;
    }
    /**
     * The description for the Data Factory Linked Service.
     * 
     */
    @Export(name="description", refs={String.class}, tree="[0]")
    private Output</* @Nullable */ String> description;

    /**
     * @return The description for the Data Factory Linked Service.
     * 
     */
    public Output<Optional<String>> description() {
        return Codegen.optional(this.description);
    }
    /**
     * The cluster_id of an existing cluster within the linked ADB instance.
     * 
     */
    @Export(name="existingClusterId", refs={String.class}, tree="[0]")
    private Output</* @Nullable */ String> existingClusterId;

    /**
     * @return The cluster_id of an existing cluster within the linked ADB instance.
     * 
     */
    public Output<Optional<String>> existingClusterId() {
        return Codegen.optional(this.existingClusterId);
    }
    /**
     * Leverages an instance pool within the linked ADB instance as one `instance_pool` block defined below.
     * 
     */
    @Export(name="instancePool", refs={LinkedServiceAzureDatabricksInstancePool.class}, tree="[0]")
    private Output</* @Nullable */ LinkedServiceAzureDatabricksInstancePool> instancePool;

    /**
     * @return Leverages an instance pool within the linked ADB instance as one `instance_pool` block defined below.
     * 
     */
    public Output<Optional<LinkedServiceAzureDatabricksInstancePool>> instancePool() {
        return Codegen.optional(this.instancePool);
    }
    /**
     * The integration runtime reference to associate with the Data Factory Linked Service.
     * 
     */
    @Export(name="integrationRuntimeName", refs={String.class}, tree="[0]")
    private Output</* @Nullable */ String> integrationRuntimeName;

    /**
     * @return The integration runtime reference to associate with the Data Factory Linked Service.
     * 
     */
    public Output<Optional<String>> integrationRuntimeName() {
        return Codegen.optional(this.integrationRuntimeName);
    }
    /**
     * Authenticate to ADB via Azure Key Vault Linked Service as defined in the `key_vault_password` block below.
     * 
     */
    @Export(name="keyVaultPassword", refs={LinkedServiceAzureDatabricksKeyVaultPassword.class}, tree="[0]")
    private Output</* @Nullable */ LinkedServiceAzureDatabricksKeyVaultPassword> keyVaultPassword;

    /**
     * @return Authenticate to ADB via Azure Key Vault Linked Service as defined in the `key_vault_password` block below.
     * 
     */
    public Output<Optional<LinkedServiceAzureDatabricksKeyVaultPassword>> keyVaultPassword() {
        return Codegen.optional(this.keyVaultPassword);
    }
    /**
     * Authenticate to ADB via managed service identity.
     * 
     */
    @Export(name="msiWorkSpaceResourceId", refs={String.class}, tree="[0]")
    private Output</* @Nullable */ String> msiWorkSpaceResourceId;

    /**
     * @return Authenticate to ADB via managed service identity.
     * 
     */
    public Output<Optional<String>> msiWorkSpaceResourceId() {
        return Codegen.optional(this.msiWorkSpaceResourceId);
    }
    /**
     * Specifies the name of the Data Factory Linked Service. Changing this forces a new resource to be created. Must be unique within a data factory. See the [Microsoft documentation](https://docs.microsoft.com/azure/data-factory/naming-rules) for all restrictions.
     * 
     */
    @Export(name="name", refs={String.class}, tree="[0]")
    private Output<String> name;

    /**
     * @return Specifies the name of the Data Factory Linked Service. Changing this forces a new resource to be created. Must be unique within a data factory. See the [Microsoft documentation](https://docs.microsoft.com/azure/data-factory/naming-rules) for all restrictions.
     * 
     */
    public Output<String> name() {
        return this.name;
    }
    /**
     * Creates new clusters within the linked ADB instance as defined in the `new_cluster_config` block below.
     * 
     */
    @Export(name="newClusterConfig", refs={LinkedServiceAzureDatabricksNewClusterConfig.class}, tree="[0]")
    private Output</* @Nullable */ LinkedServiceAzureDatabricksNewClusterConfig> newClusterConfig;

    /**
     * @return Creates new clusters within the linked ADB instance as defined in the `new_cluster_config` block below.
     * 
     */
    public Output<Optional<LinkedServiceAzureDatabricksNewClusterConfig>> newClusterConfig() {
        return Codegen.optional(this.newClusterConfig);
    }
    /**
     * A map of parameters to associate with the Data Factory Linked Service.
     * 
     */
    @Export(name="parameters", refs={Map.class,String.class}, tree="[0,1,1]")
    private Output</* @Nullable */ Map<String,String>> parameters;

    /**
     * @return A map of parameters to associate with the Data Factory Linked Service.
     * 
     */
    public Output<Optional<Map<String,String>>> parameters() {
        return Codegen.optional(this.parameters);
    }

    /**
     *
     * @param name The _unique_ name of the resulting resource.
     */
    public LinkedServiceAzureDatabricks(String name) {
        this(name, LinkedServiceAzureDatabricksArgs.Empty);
    }
    /**
     *
     * @param name The _unique_ name of the resulting resource.
     * @param args The arguments to use to populate this resource's properties.
     */
    public LinkedServiceAzureDatabricks(String name, LinkedServiceAzureDatabricksArgs args) {
        this(name, args, null);
    }
    /**
     *
     * @param name The _unique_ name of the resulting resource.
     * @param args The arguments to use to populate this resource's properties.
     * @param options A bag of options that control this resource's behavior.
     */
    public LinkedServiceAzureDatabricks(String name, LinkedServiceAzureDatabricksArgs args, @Nullable com.pulumi.resources.CustomResourceOptions options) {
        super("azure:datafactory/linkedServiceAzureDatabricks:LinkedServiceAzureDatabricks", name, args == null ? LinkedServiceAzureDatabricksArgs.Empty : args, makeResourceOptions(options, Codegen.empty()));
    }

    private LinkedServiceAzureDatabricks(String name, Output<String> id, @Nullable LinkedServiceAzureDatabricksState state, @Nullable com.pulumi.resources.CustomResourceOptions options) {
        super("azure:datafactory/linkedServiceAzureDatabricks:LinkedServiceAzureDatabricks", name, state, makeResourceOptions(options, id));
    }

    private static com.pulumi.resources.CustomResourceOptions makeResourceOptions(@Nullable com.pulumi.resources.CustomResourceOptions options, @Nullable Output<String> id) {
        var defaultOptions = com.pulumi.resources.CustomResourceOptions.builder()
            .version(Utilities.getVersion())
            .additionalSecretOutputs(List.of(
                "accessToken"
            ))
            .build();
        return com.pulumi.resources.CustomResourceOptions.merge(defaultOptions, options, id);
    }

    /**
     * Get an existing Host resource's state with the given name, ID, and optional extra
     * properties used to qualify the lookup.
     *
     * @param name The _unique_ name of the resulting resource.
     * @param id The _unique_ provider ID of the resource to lookup.
     * @param state
     * @param options Optional settings to control the behavior of the CustomResource.
     */
    public static LinkedServiceAzureDatabricks get(String name, Output<String> id, @Nullable LinkedServiceAzureDatabricksState state, @Nullable com.pulumi.resources.CustomResourceOptions options) {
        return new LinkedServiceAzureDatabricks(name, id, state, options);
    }
}
