// *** WARNING: this file was generated by pulumi-java-gen. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

package com.pulumi.azure.synapse;

import com.pulumi.azure.synapse.inputs.SparkPoolAutoPauseArgs;
import com.pulumi.azure.synapse.inputs.SparkPoolAutoScaleArgs;
import com.pulumi.azure.synapse.inputs.SparkPoolLibraryRequirementArgs;
import com.pulumi.azure.synapse.inputs.SparkPoolSparkConfigArgs;
import com.pulumi.core.Output;
import com.pulumi.core.annotations.Import;
import com.pulumi.exceptions.MissingRequiredPropertyException;
import java.lang.Boolean;
import java.lang.Integer;
import java.lang.String;
import java.util.Map;
import java.util.Objects;
import java.util.Optional;
import javax.annotation.Nullable;


public final class SparkPoolArgs extends com.pulumi.resources.ResourceArgs {

    public static final SparkPoolArgs Empty = new SparkPoolArgs();

    /**
     * An `auto_pause` block as defined below.
     * 
     */
    @Import(name="autoPause")
    private @Nullable Output<SparkPoolAutoPauseArgs> autoPause;

    /**
     * @return An `auto_pause` block as defined below.
     * 
     */
    public Optional<Output<SparkPoolAutoPauseArgs>> autoPause() {
        return Optional.ofNullable(this.autoPause);
    }

    /**
     * An `auto_scale` block as defined below. Exactly one of `node_count` or `auto_scale` must be specified.
     * 
     */
    @Import(name="autoScale")
    private @Nullable Output<SparkPoolAutoScaleArgs> autoScale;

    /**
     * @return An `auto_scale` block as defined below. Exactly one of `node_count` or `auto_scale` must be specified.
     * 
     */
    public Optional<Output<SparkPoolAutoScaleArgs>> autoScale() {
        return Optional.ofNullable(this.autoScale);
    }

    /**
     * The cache size in the Spark Pool.
     * 
     */
    @Import(name="cacheSize")
    private @Nullable Output<Integer> cacheSize;

    /**
     * @return The cache size in the Spark Pool.
     * 
     */
    public Optional<Output<Integer>> cacheSize() {
        return Optional.ofNullable(this.cacheSize);
    }

    /**
     * Indicates whether compute isolation is enabled or not. Defaults to `false`.
     * 
     */
    @Import(name="computeIsolationEnabled")
    private @Nullable Output<Boolean> computeIsolationEnabled;

    /**
     * @return Indicates whether compute isolation is enabled or not. Defaults to `false`.
     * 
     */
    public Optional<Output<Boolean>> computeIsolationEnabled() {
        return Optional.ofNullable(this.computeIsolationEnabled);
    }

    /**
     * Indicates whether Dynamic Executor Allocation is enabled or not. Defaults to `false`.
     * 
     */
    @Import(name="dynamicExecutorAllocationEnabled")
    private @Nullable Output<Boolean> dynamicExecutorAllocationEnabled;

    /**
     * @return Indicates whether Dynamic Executor Allocation is enabled or not. Defaults to `false`.
     * 
     */
    public Optional<Output<Boolean>> dynamicExecutorAllocationEnabled() {
        return Optional.ofNullable(this.dynamicExecutorAllocationEnabled);
    }

    /**
     * A `library_requirement` block as defined below.
     * 
     */
    @Import(name="libraryRequirement")
    private @Nullable Output<SparkPoolLibraryRequirementArgs> libraryRequirement;

    /**
     * @return A `library_requirement` block as defined below.
     * 
     */
    public Optional<Output<SparkPoolLibraryRequirementArgs>> libraryRequirement() {
        return Optional.ofNullable(this.libraryRequirement);
    }

    /**
     * The maximum number of executors allocated only when `dynamic_executor_allocation_enabled` set to `true`.
     * 
     */
    @Import(name="maxExecutors")
    private @Nullable Output<Integer> maxExecutors;

    /**
     * @return The maximum number of executors allocated only when `dynamic_executor_allocation_enabled` set to `true`.
     * 
     */
    public Optional<Output<Integer>> maxExecutors() {
        return Optional.ofNullable(this.maxExecutors);
    }

    /**
     * The minimum number of executors allocated only when `dynamic_executor_allocation_enabled` set to `true`.
     * 
     */
    @Import(name="minExecutors")
    private @Nullable Output<Integer> minExecutors;

    /**
     * @return The minimum number of executors allocated only when `dynamic_executor_allocation_enabled` set to `true`.
     * 
     */
    public Optional<Output<Integer>> minExecutors() {
        return Optional.ofNullable(this.minExecutors);
    }

    /**
     * The name which should be used for this Synapse Spark Pool. Changing this forces a new Synapse Spark Pool to be created.
     * 
     */
    @Import(name="name")
    private @Nullable Output<String> name;

    /**
     * @return The name which should be used for this Synapse Spark Pool. Changing this forces a new Synapse Spark Pool to be created.
     * 
     */
    public Optional<Output<String>> name() {
        return Optional.ofNullable(this.name);
    }

    /**
     * The number of nodes in the Spark Pool. Exactly one of `node_count` or `auto_scale` must be specified.
     * 
     */
    @Import(name="nodeCount")
    private @Nullable Output<Integer> nodeCount;

    /**
     * @return The number of nodes in the Spark Pool. Exactly one of `node_count` or `auto_scale` must be specified.
     * 
     */
    public Optional<Output<Integer>> nodeCount() {
        return Optional.ofNullable(this.nodeCount);
    }

    /**
     * The level of node in the Spark Pool. Possible values are `Small`, `Medium`, `Large`, `None`, `XLarge`, `XXLarge` and `XXXLarge`.
     * 
     */
    @Import(name="nodeSize", required=true)
    private Output<String> nodeSize;

    /**
     * @return The level of node in the Spark Pool. Possible values are `Small`, `Medium`, `Large`, `None`, `XLarge`, `XXLarge` and `XXXLarge`.
     * 
     */
    public Output<String> nodeSize() {
        return this.nodeSize;
    }

    /**
     * The kind of nodes that the Spark Pool provides. Possible values are `HardwareAcceleratedFPGA`, `HardwareAcceleratedGPU`, `MemoryOptimized`, and `None`.
     * 
     */
    @Import(name="nodeSizeFamily", required=true)
    private Output<String> nodeSizeFamily;

    /**
     * @return The kind of nodes that the Spark Pool provides. Possible values are `HardwareAcceleratedFPGA`, `HardwareAcceleratedGPU`, `MemoryOptimized`, and `None`.
     * 
     */
    public Output<String> nodeSizeFamily() {
        return this.nodeSizeFamily;
    }

    /**
     * Indicates whether session level packages are enabled or not. Defaults to `false`.
     * 
     */
    @Import(name="sessionLevelPackagesEnabled")
    private @Nullable Output<Boolean> sessionLevelPackagesEnabled;

    /**
     * @return Indicates whether session level packages are enabled or not. Defaults to `false`.
     * 
     */
    public Optional<Output<Boolean>> sessionLevelPackagesEnabled() {
        return Optional.ofNullable(this.sessionLevelPackagesEnabled);
    }

    /**
     * A `spark_config` block as defined below.
     * 
     */
    @Import(name="sparkConfig")
    private @Nullable Output<SparkPoolSparkConfigArgs> sparkConfig;

    /**
     * @return A `spark_config` block as defined below.
     * 
     */
    public Optional<Output<SparkPoolSparkConfigArgs>> sparkConfig() {
        return Optional.ofNullable(this.sparkConfig);
    }

    /**
     * The Spark events folder. Defaults to `/events`.
     * 
     */
    @Import(name="sparkEventsFolder")
    private @Nullable Output<String> sparkEventsFolder;

    /**
     * @return The Spark events folder. Defaults to `/events`.
     * 
     */
    public Optional<Output<String>> sparkEventsFolder() {
        return Optional.ofNullable(this.sparkEventsFolder);
    }

    /**
     * The default folder where Spark logs will be written. Defaults to `/logs`.
     * 
     */
    @Import(name="sparkLogFolder")
    private @Nullable Output<String> sparkLogFolder;

    /**
     * @return The default folder where Spark logs will be written. Defaults to `/logs`.
     * 
     */
    public Optional<Output<String>> sparkLogFolder() {
        return Optional.ofNullable(this.sparkLogFolder);
    }

    /**
     * The Apache Spark version. Possible values are `2.4` , `3.1` , `3.2` and `3.3`. Defaults to `2.4`.
     * 
     */
    @Import(name="sparkVersion")
    private @Nullable Output<String> sparkVersion;

    /**
     * @return The Apache Spark version. Possible values are `2.4` , `3.1` , `3.2` and `3.3`. Defaults to `2.4`.
     * 
     */
    public Optional<Output<String>> sparkVersion() {
        return Optional.ofNullable(this.sparkVersion);
    }

    /**
     * The ID of the Synapse Workspace where the Synapse Spark Pool should exist. Changing this forces a new Synapse Spark Pool to be created.
     * 
     */
    @Import(name="synapseWorkspaceId", required=true)
    private Output<String> synapseWorkspaceId;

    /**
     * @return The ID of the Synapse Workspace where the Synapse Spark Pool should exist. Changing this forces a new Synapse Spark Pool to be created.
     * 
     */
    public Output<String> synapseWorkspaceId() {
        return this.synapseWorkspaceId;
    }

    /**
     * A mapping of tags which should be assigned to the Synapse Spark Pool.
     * 
     */
    @Import(name="tags")
    private @Nullable Output<Map<String,String>> tags;

    /**
     * @return A mapping of tags which should be assigned to the Synapse Spark Pool.
     * 
     */
    public Optional<Output<Map<String,String>>> tags() {
        return Optional.ofNullable(this.tags);
    }

    private SparkPoolArgs() {}

    private SparkPoolArgs(SparkPoolArgs $) {
        this.autoPause = $.autoPause;
        this.autoScale = $.autoScale;
        this.cacheSize = $.cacheSize;
        this.computeIsolationEnabled = $.computeIsolationEnabled;
        this.dynamicExecutorAllocationEnabled = $.dynamicExecutorAllocationEnabled;
        this.libraryRequirement = $.libraryRequirement;
        this.maxExecutors = $.maxExecutors;
        this.minExecutors = $.minExecutors;
        this.name = $.name;
        this.nodeCount = $.nodeCount;
        this.nodeSize = $.nodeSize;
        this.nodeSizeFamily = $.nodeSizeFamily;
        this.sessionLevelPackagesEnabled = $.sessionLevelPackagesEnabled;
        this.sparkConfig = $.sparkConfig;
        this.sparkEventsFolder = $.sparkEventsFolder;
        this.sparkLogFolder = $.sparkLogFolder;
        this.sparkVersion = $.sparkVersion;
        this.synapseWorkspaceId = $.synapseWorkspaceId;
        this.tags = $.tags;
    }

    public static Builder builder() {
        return new Builder();
    }
    public static Builder builder(SparkPoolArgs defaults) {
        return new Builder(defaults);
    }

    public static final class Builder {
        private SparkPoolArgs $;

        public Builder() {
            $ = new SparkPoolArgs();
        }

        public Builder(SparkPoolArgs defaults) {
            $ = new SparkPoolArgs(Objects.requireNonNull(defaults));
        }

        /**
         * @param autoPause An `auto_pause` block as defined below.
         * 
         * @return builder
         * 
         */
        public Builder autoPause(@Nullable Output<SparkPoolAutoPauseArgs> autoPause) {
            $.autoPause = autoPause;
            return this;
        }

        /**
         * @param autoPause An `auto_pause` block as defined below.
         * 
         * @return builder
         * 
         */
        public Builder autoPause(SparkPoolAutoPauseArgs autoPause) {
            return autoPause(Output.of(autoPause));
        }

        /**
         * @param autoScale An `auto_scale` block as defined below. Exactly one of `node_count` or `auto_scale` must be specified.
         * 
         * @return builder
         * 
         */
        public Builder autoScale(@Nullable Output<SparkPoolAutoScaleArgs> autoScale) {
            $.autoScale = autoScale;
            return this;
        }

        /**
         * @param autoScale An `auto_scale` block as defined below. Exactly one of `node_count` or `auto_scale` must be specified.
         * 
         * @return builder
         * 
         */
        public Builder autoScale(SparkPoolAutoScaleArgs autoScale) {
            return autoScale(Output.of(autoScale));
        }

        /**
         * @param cacheSize The cache size in the Spark Pool.
         * 
         * @return builder
         * 
         */
        public Builder cacheSize(@Nullable Output<Integer> cacheSize) {
            $.cacheSize = cacheSize;
            return this;
        }

        /**
         * @param cacheSize The cache size in the Spark Pool.
         * 
         * @return builder
         * 
         */
        public Builder cacheSize(Integer cacheSize) {
            return cacheSize(Output.of(cacheSize));
        }

        /**
         * @param computeIsolationEnabled Indicates whether compute isolation is enabled or not. Defaults to `false`.
         * 
         * @return builder
         * 
         */
        public Builder computeIsolationEnabled(@Nullable Output<Boolean> computeIsolationEnabled) {
            $.computeIsolationEnabled = computeIsolationEnabled;
            return this;
        }

        /**
         * @param computeIsolationEnabled Indicates whether compute isolation is enabled or not. Defaults to `false`.
         * 
         * @return builder
         * 
         */
        public Builder computeIsolationEnabled(Boolean computeIsolationEnabled) {
            return computeIsolationEnabled(Output.of(computeIsolationEnabled));
        }

        /**
         * @param dynamicExecutorAllocationEnabled Indicates whether Dynamic Executor Allocation is enabled or not. Defaults to `false`.
         * 
         * @return builder
         * 
         */
        public Builder dynamicExecutorAllocationEnabled(@Nullable Output<Boolean> dynamicExecutorAllocationEnabled) {
            $.dynamicExecutorAllocationEnabled = dynamicExecutorAllocationEnabled;
            return this;
        }

        /**
         * @param dynamicExecutorAllocationEnabled Indicates whether Dynamic Executor Allocation is enabled or not. Defaults to `false`.
         * 
         * @return builder
         * 
         */
        public Builder dynamicExecutorAllocationEnabled(Boolean dynamicExecutorAllocationEnabled) {
            return dynamicExecutorAllocationEnabled(Output.of(dynamicExecutorAllocationEnabled));
        }

        /**
         * @param libraryRequirement A `library_requirement` block as defined below.
         * 
         * @return builder
         * 
         */
        public Builder libraryRequirement(@Nullable Output<SparkPoolLibraryRequirementArgs> libraryRequirement) {
            $.libraryRequirement = libraryRequirement;
            return this;
        }

        /**
         * @param libraryRequirement A `library_requirement` block as defined below.
         * 
         * @return builder
         * 
         */
        public Builder libraryRequirement(SparkPoolLibraryRequirementArgs libraryRequirement) {
            return libraryRequirement(Output.of(libraryRequirement));
        }

        /**
         * @param maxExecutors The maximum number of executors allocated only when `dynamic_executor_allocation_enabled` set to `true`.
         * 
         * @return builder
         * 
         */
        public Builder maxExecutors(@Nullable Output<Integer> maxExecutors) {
            $.maxExecutors = maxExecutors;
            return this;
        }

        /**
         * @param maxExecutors The maximum number of executors allocated only when `dynamic_executor_allocation_enabled` set to `true`.
         * 
         * @return builder
         * 
         */
        public Builder maxExecutors(Integer maxExecutors) {
            return maxExecutors(Output.of(maxExecutors));
        }

        /**
         * @param minExecutors The minimum number of executors allocated only when `dynamic_executor_allocation_enabled` set to `true`.
         * 
         * @return builder
         * 
         */
        public Builder minExecutors(@Nullable Output<Integer> minExecutors) {
            $.minExecutors = minExecutors;
            return this;
        }

        /**
         * @param minExecutors The minimum number of executors allocated only when `dynamic_executor_allocation_enabled` set to `true`.
         * 
         * @return builder
         * 
         */
        public Builder minExecutors(Integer minExecutors) {
            return minExecutors(Output.of(minExecutors));
        }

        /**
         * @param name The name which should be used for this Synapse Spark Pool. Changing this forces a new Synapse Spark Pool to be created.
         * 
         * @return builder
         * 
         */
        public Builder name(@Nullable Output<String> name) {
            $.name = name;
            return this;
        }

        /**
         * @param name The name which should be used for this Synapse Spark Pool. Changing this forces a new Synapse Spark Pool to be created.
         * 
         * @return builder
         * 
         */
        public Builder name(String name) {
            return name(Output.of(name));
        }

        /**
         * @param nodeCount The number of nodes in the Spark Pool. Exactly one of `node_count` or `auto_scale` must be specified.
         * 
         * @return builder
         * 
         */
        public Builder nodeCount(@Nullable Output<Integer> nodeCount) {
            $.nodeCount = nodeCount;
            return this;
        }

        /**
         * @param nodeCount The number of nodes in the Spark Pool. Exactly one of `node_count` or `auto_scale` must be specified.
         * 
         * @return builder
         * 
         */
        public Builder nodeCount(Integer nodeCount) {
            return nodeCount(Output.of(nodeCount));
        }

        /**
         * @param nodeSize The level of node in the Spark Pool. Possible values are `Small`, `Medium`, `Large`, `None`, `XLarge`, `XXLarge` and `XXXLarge`.
         * 
         * @return builder
         * 
         */
        public Builder nodeSize(Output<String> nodeSize) {
            $.nodeSize = nodeSize;
            return this;
        }

        /**
         * @param nodeSize The level of node in the Spark Pool. Possible values are `Small`, `Medium`, `Large`, `None`, `XLarge`, `XXLarge` and `XXXLarge`.
         * 
         * @return builder
         * 
         */
        public Builder nodeSize(String nodeSize) {
            return nodeSize(Output.of(nodeSize));
        }

        /**
         * @param nodeSizeFamily The kind of nodes that the Spark Pool provides. Possible values are `HardwareAcceleratedFPGA`, `HardwareAcceleratedGPU`, `MemoryOptimized`, and `None`.
         * 
         * @return builder
         * 
         */
        public Builder nodeSizeFamily(Output<String> nodeSizeFamily) {
            $.nodeSizeFamily = nodeSizeFamily;
            return this;
        }

        /**
         * @param nodeSizeFamily The kind of nodes that the Spark Pool provides. Possible values are `HardwareAcceleratedFPGA`, `HardwareAcceleratedGPU`, `MemoryOptimized`, and `None`.
         * 
         * @return builder
         * 
         */
        public Builder nodeSizeFamily(String nodeSizeFamily) {
            return nodeSizeFamily(Output.of(nodeSizeFamily));
        }

        /**
         * @param sessionLevelPackagesEnabled Indicates whether session level packages are enabled or not. Defaults to `false`.
         * 
         * @return builder
         * 
         */
        public Builder sessionLevelPackagesEnabled(@Nullable Output<Boolean> sessionLevelPackagesEnabled) {
            $.sessionLevelPackagesEnabled = sessionLevelPackagesEnabled;
            return this;
        }

        /**
         * @param sessionLevelPackagesEnabled Indicates whether session level packages are enabled or not. Defaults to `false`.
         * 
         * @return builder
         * 
         */
        public Builder sessionLevelPackagesEnabled(Boolean sessionLevelPackagesEnabled) {
            return sessionLevelPackagesEnabled(Output.of(sessionLevelPackagesEnabled));
        }

        /**
         * @param sparkConfig A `spark_config` block as defined below.
         * 
         * @return builder
         * 
         */
        public Builder sparkConfig(@Nullable Output<SparkPoolSparkConfigArgs> sparkConfig) {
            $.sparkConfig = sparkConfig;
            return this;
        }

        /**
         * @param sparkConfig A `spark_config` block as defined below.
         * 
         * @return builder
         * 
         */
        public Builder sparkConfig(SparkPoolSparkConfigArgs sparkConfig) {
            return sparkConfig(Output.of(sparkConfig));
        }

        /**
         * @param sparkEventsFolder The Spark events folder. Defaults to `/events`.
         * 
         * @return builder
         * 
         */
        public Builder sparkEventsFolder(@Nullable Output<String> sparkEventsFolder) {
            $.sparkEventsFolder = sparkEventsFolder;
            return this;
        }

        /**
         * @param sparkEventsFolder The Spark events folder. Defaults to `/events`.
         * 
         * @return builder
         * 
         */
        public Builder sparkEventsFolder(String sparkEventsFolder) {
            return sparkEventsFolder(Output.of(sparkEventsFolder));
        }

        /**
         * @param sparkLogFolder The default folder where Spark logs will be written. Defaults to `/logs`.
         * 
         * @return builder
         * 
         */
        public Builder sparkLogFolder(@Nullable Output<String> sparkLogFolder) {
            $.sparkLogFolder = sparkLogFolder;
            return this;
        }

        /**
         * @param sparkLogFolder The default folder where Spark logs will be written. Defaults to `/logs`.
         * 
         * @return builder
         * 
         */
        public Builder sparkLogFolder(String sparkLogFolder) {
            return sparkLogFolder(Output.of(sparkLogFolder));
        }

        /**
         * @param sparkVersion The Apache Spark version. Possible values are `2.4` , `3.1` , `3.2` and `3.3`. Defaults to `2.4`.
         * 
         * @return builder
         * 
         */
        public Builder sparkVersion(@Nullable Output<String> sparkVersion) {
            $.sparkVersion = sparkVersion;
            return this;
        }

        /**
         * @param sparkVersion The Apache Spark version. Possible values are `2.4` , `3.1` , `3.2` and `3.3`. Defaults to `2.4`.
         * 
         * @return builder
         * 
         */
        public Builder sparkVersion(String sparkVersion) {
            return sparkVersion(Output.of(sparkVersion));
        }

        /**
         * @param synapseWorkspaceId The ID of the Synapse Workspace where the Synapse Spark Pool should exist. Changing this forces a new Synapse Spark Pool to be created.
         * 
         * @return builder
         * 
         */
        public Builder synapseWorkspaceId(Output<String> synapseWorkspaceId) {
            $.synapseWorkspaceId = synapseWorkspaceId;
            return this;
        }

        /**
         * @param synapseWorkspaceId The ID of the Synapse Workspace where the Synapse Spark Pool should exist. Changing this forces a new Synapse Spark Pool to be created.
         * 
         * @return builder
         * 
         */
        public Builder synapseWorkspaceId(String synapseWorkspaceId) {
            return synapseWorkspaceId(Output.of(synapseWorkspaceId));
        }

        /**
         * @param tags A mapping of tags which should be assigned to the Synapse Spark Pool.
         * 
         * @return builder
         * 
         */
        public Builder tags(@Nullable Output<Map<String,String>> tags) {
            $.tags = tags;
            return this;
        }

        /**
         * @param tags A mapping of tags which should be assigned to the Synapse Spark Pool.
         * 
         * @return builder
         * 
         */
        public Builder tags(Map<String,String> tags) {
            return tags(Output.of(tags));
        }

        public SparkPoolArgs build() {
            if ($.nodeSize == null) {
                throw new MissingRequiredPropertyException("SparkPoolArgs", "nodeSize");
            }
            if ($.nodeSizeFamily == null) {
                throw new MissingRequiredPropertyException("SparkPoolArgs", "nodeSizeFamily");
            }
            if ($.synapseWorkspaceId == null) {
                throw new MissingRequiredPropertyException("SparkPoolArgs", "synapseWorkspaceId");
            }
            return $;
        }
    }

}
