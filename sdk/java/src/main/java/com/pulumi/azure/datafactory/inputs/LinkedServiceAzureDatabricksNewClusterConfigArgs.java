// *** WARNING: this file was generated by pulumi-java-gen. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

package com.pulumi.azure.datafactory.inputs;

import com.pulumi.core.Output;
import com.pulumi.core.annotations.Import;
import com.pulumi.exceptions.MissingRequiredPropertyException;
import java.lang.Integer;
import java.lang.String;
import java.util.List;
import java.util.Map;
import java.util.Objects;
import java.util.Optional;
import javax.annotation.Nullable;


public final class LinkedServiceAzureDatabricksNewClusterConfigArgs extends com.pulumi.resources.ResourceArgs {

    public static final LinkedServiceAzureDatabricksNewClusterConfigArgs Empty = new LinkedServiceAzureDatabricksNewClusterConfigArgs();

    /**
     * Spark version of a the cluster.
     * 
     */
    @Import(name="clusterVersion", required=true)
    private Output<String> clusterVersion;

    /**
     * @return Spark version of a the cluster.
     * 
     */
    public Output<String> clusterVersion() {
        return this.clusterVersion;
    }

    /**
     * Tags for the cluster resource.
     * 
     */
    @Import(name="customTags")
    private @Nullable Output<Map<String,String>> customTags;

    /**
     * @return Tags for the cluster resource.
     * 
     */
    public Optional<Output<Map<String,String>>> customTags() {
        return Optional.ofNullable(this.customTags);
    }

    /**
     * Driver node type for the cluster.
     * 
     */
    @Import(name="driverNodeType")
    private @Nullable Output<String> driverNodeType;

    /**
     * @return Driver node type for the cluster.
     * 
     */
    public Optional<Output<String>> driverNodeType() {
        return Optional.ofNullable(this.driverNodeType);
    }

    /**
     * User defined initialization scripts for the cluster.
     * 
     */
    @Import(name="initScripts")
    private @Nullable Output<List<String>> initScripts;

    /**
     * @return User defined initialization scripts for the cluster.
     * 
     */
    public Optional<Output<List<String>>> initScripts() {
        return Optional.ofNullable(this.initScripts);
    }

    /**
     * Location to deliver Spark driver, worker, and event logs.
     * 
     */
    @Import(name="logDestination")
    private @Nullable Output<String> logDestination;

    /**
     * @return Location to deliver Spark driver, worker, and event logs.
     * 
     */
    public Optional<Output<String>> logDestination() {
        return Optional.ofNullable(this.logDestination);
    }

    /**
     * Specifies the maximum number of worker nodes. It should be between 1 and 25000.
     * 
     */
    @Import(name="maxNumberOfWorkers")
    private @Nullable Output<Integer> maxNumberOfWorkers;

    /**
     * @return Specifies the maximum number of worker nodes. It should be between 1 and 25000.
     * 
     */
    public Optional<Output<Integer>> maxNumberOfWorkers() {
        return Optional.ofNullable(this.maxNumberOfWorkers);
    }

    /**
     * Specifies the minimum number of worker nodes. It should be between 1 and 25000. It defaults to `1`.
     * 
     */
    @Import(name="minNumberOfWorkers")
    private @Nullable Output<Integer> minNumberOfWorkers;

    /**
     * @return Specifies the minimum number of worker nodes. It should be between 1 and 25000. It defaults to `1`.
     * 
     */
    public Optional<Output<Integer>> minNumberOfWorkers() {
        return Optional.ofNullable(this.minNumberOfWorkers);
    }

    /**
     * Node type for the new cluster.
     * 
     */
    @Import(name="nodeType", required=true)
    private Output<String> nodeType;

    /**
     * @return Node type for the new cluster.
     * 
     */
    public Output<String> nodeType() {
        return this.nodeType;
    }

    /**
     * User-specified Spark configuration variables key-value pairs.
     * 
     */
    @Import(name="sparkConfig")
    private @Nullable Output<Map<String,String>> sparkConfig;

    /**
     * @return User-specified Spark configuration variables key-value pairs.
     * 
     */
    public Optional<Output<Map<String,String>>> sparkConfig() {
        return Optional.ofNullable(this.sparkConfig);
    }

    /**
     * User-specified Spark environment variables key-value pairs.
     * 
     */
    @Import(name="sparkEnvironmentVariables")
    private @Nullable Output<Map<String,String>> sparkEnvironmentVariables;

    /**
     * @return User-specified Spark environment variables key-value pairs.
     * 
     */
    public Optional<Output<Map<String,String>>> sparkEnvironmentVariables() {
        return Optional.ofNullable(this.sparkEnvironmentVariables);
    }

    private LinkedServiceAzureDatabricksNewClusterConfigArgs() {}

    private LinkedServiceAzureDatabricksNewClusterConfigArgs(LinkedServiceAzureDatabricksNewClusterConfigArgs $) {
        this.clusterVersion = $.clusterVersion;
        this.customTags = $.customTags;
        this.driverNodeType = $.driverNodeType;
        this.initScripts = $.initScripts;
        this.logDestination = $.logDestination;
        this.maxNumberOfWorkers = $.maxNumberOfWorkers;
        this.minNumberOfWorkers = $.minNumberOfWorkers;
        this.nodeType = $.nodeType;
        this.sparkConfig = $.sparkConfig;
        this.sparkEnvironmentVariables = $.sparkEnvironmentVariables;
    }

    public static Builder builder() {
        return new Builder();
    }
    public static Builder builder(LinkedServiceAzureDatabricksNewClusterConfigArgs defaults) {
        return new Builder(defaults);
    }

    public static final class Builder {
        private LinkedServiceAzureDatabricksNewClusterConfigArgs $;

        public Builder() {
            $ = new LinkedServiceAzureDatabricksNewClusterConfigArgs();
        }

        public Builder(LinkedServiceAzureDatabricksNewClusterConfigArgs defaults) {
            $ = new LinkedServiceAzureDatabricksNewClusterConfigArgs(Objects.requireNonNull(defaults));
        }

        /**
         * @param clusterVersion Spark version of a the cluster.
         * 
         * @return builder
         * 
         */
        public Builder clusterVersion(Output<String> clusterVersion) {
            $.clusterVersion = clusterVersion;
            return this;
        }

        /**
         * @param clusterVersion Spark version of a the cluster.
         * 
         * @return builder
         * 
         */
        public Builder clusterVersion(String clusterVersion) {
            return clusterVersion(Output.of(clusterVersion));
        }

        /**
         * @param customTags Tags for the cluster resource.
         * 
         * @return builder
         * 
         */
        public Builder customTags(@Nullable Output<Map<String,String>> customTags) {
            $.customTags = customTags;
            return this;
        }

        /**
         * @param customTags Tags for the cluster resource.
         * 
         * @return builder
         * 
         */
        public Builder customTags(Map<String,String> customTags) {
            return customTags(Output.of(customTags));
        }

        /**
         * @param driverNodeType Driver node type for the cluster.
         * 
         * @return builder
         * 
         */
        public Builder driverNodeType(@Nullable Output<String> driverNodeType) {
            $.driverNodeType = driverNodeType;
            return this;
        }

        /**
         * @param driverNodeType Driver node type for the cluster.
         * 
         * @return builder
         * 
         */
        public Builder driverNodeType(String driverNodeType) {
            return driverNodeType(Output.of(driverNodeType));
        }

        /**
         * @param initScripts User defined initialization scripts for the cluster.
         * 
         * @return builder
         * 
         */
        public Builder initScripts(@Nullable Output<List<String>> initScripts) {
            $.initScripts = initScripts;
            return this;
        }

        /**
         * @param initScripts User defined initialization scripts for the cluster.
         * 
         * @return builder
         * 
         */
        public Builder initScripts(List<String> initScripts) {
            return initScripts(Output.of(initScripts));
        }

        /**
         * @param initScripts User defined initialization scripts for the cluster.
         * 
         * @return builder
         * 
         */
        public Builder initScripts(String... initScripts) {
            return initScripts(List.of(initScripts));
        }

        /**
         * @param logDestination Location to deliver Spark driver, worker, and event logs.
         * 
         * @return builder
         * 
         */
        public Builder logDestination(@Nullable Output<String> logDestination) {
            $.logDestination = logDestination;
            return this;
        }

        /**
         * @param logDestination Location to deliver Spark driver, worker, and event logs.
         * 
         * @return builder
         * 
         */
        public Builder logDestination(String logDestination) {
            return logDestination(Output.of(logDestination));
        }

        /**
         * @param maxNumberOfWorkers Specifies the maximum number of worker nodes. It should be between 1 and 25000.
         * 
         * @return builder
         * 
         */
        public Builder maxNumberOfWorkers(@Nullable Output<Integer> maxNumberOfWorkers) {
            $.maxNumberOfWorkers = maxNumberOfWorkers;
            return this;
        }

        /**
         * @param maxNumberOfWorkers Specifies the maximum number of worker nodes. It should be between 1 and 25000.
         * 
         * @return builder
         * 
         */
        public Builder maxNumberOfWorkers(Integer maxNumberOfWorkers) {
            return maxNumberOfWorkers(Output.of(maxNumberOfWorkers));
        }

        /**
         * @param minNumberOfWorkers Specifies the minimum number of worker nodes. It should be between 1 and 25000. It defaults to `1`.
         * 
         * @return builder
         * 
         */
        public Builder minNumberOfWorkers(@Nullable Output<Integer> minNumberOfWorkers) {
            $.minNumberOfWorkers = minNumberOfWorkers;
            return this;
        }

        /**
         * @param minNumberOfWorkers Specifies the minimum number of worker nodes. It should be between 1 and 25000. It defaults to `1`.
         * 
         * @return builder
         * 
         */
        public Builder minNumberOfWorkers(Integer minNumberOfWorkers) {
            return minNumberOfWorkers(Output.of(minNumberOfWorkers));
        }

        /**
         * @param nodeType Node type for the new cluster.
         * 
         * @return builder
         * 
         */
        public Builder nodeType(Output<String> nodeType) {
            $.nodeType = nodeType;
            return this;
        }

        /**
         * @param nodeType Node type for the new cluster.
         * 
         * @return builder
         * 
         */
        public Builder nodeType(String nodeType) {
            return nodeType(Output.of(nodeType));
        }

        /**
         * @param sparkConfig User-specified Spark configuration variables key-value pairs.
         * 
         * @return builder
         * 
         */
        public Builder sparkConfig(@Nullable Output<Map<String,String>> sparkConfig) {
            $.sparkConfig = sparkConfig;
            return this;
        }

        /**
         * @param sparkConfig User-specified Spark configuration variables key-value pairs.
         * 
         * @return builder
         * 
         */
        public Builder sparkConfig(Map<String,String> sparkConfig) {
            return sparkConfig(Output.of(sparkConfig));
        }

        /**
         * @param sparkEnvironmentVariables User-specified Spark environment variables key-value pairs.
         * 
         * @return builder
         * 
         */
        public Builder sparkEnvironmentVariables(@Nullable Output<Map<String,String>> sparkEnvironmentVariables) {
            $.sparkEnvironmentVariables = sparkEnvironmentVariables;
            return this;
        }

        /**
         * @param sparkEnvironmentVariables User-specified Spark environment variables key-value pairs.
         * 
         * @return builder
         * 
         */
        public Builder sparkEnvironmentVariables(Map<String,String> sparkEnvironmentVariables) {
            return sparkEnvironmentVariables(Output.of(sparkEnvironmentVariables));
        }

        public LinkedServiceAzureDatabricksNewClusterConfigArgs build() {
            if ($.clusterVersion == null) {
                throw new MissingRequiredPropertyException("LinkedServiceAzureDatabricksNewClusterConfigArgs", "clusterVersion");
            }
            if ($.nodeType == null) {
                throw new MissingRequiredPropertyException("LinkedServiceAzureDatabricksNewClusterConfigArgs", "nodeType");
            }
            return $;
        }
    }

}
