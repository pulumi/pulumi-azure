// *** WARNING: this file was generated by pulumi-java-gen. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

package com.pulumi.azure.hdinsight;

import com.pulumi.azure.Utilities;
import com.pulumi.azure.hdinsight.SparkClusterArgs;
import com.pulumi.azure.hdinsight.inputs.SparkClusterState;
import com.pulumi.azure.hdinsight.outputs.SparkClusterComponentVersion;
import com.pulumi.azure.hdinsight.outputs.SparkClusterGateway;
import com.pulumi.azure.hdinsight.outputs.SparkClusterMetastores;
import com.pulumi.azure.hdinsight.outputs.SparkClusterMonitor;
import com.pulumi.azure.hdinsight.outputs.SparkClusterNetwork;
import com.pulumi.azure.hdinsight.outputs.SparkClusterRoles;
import com.pulumi.azure.hdinsight.outputs.SparkClusterSecurityProfile;
import com.pulumi.azure.hdinsight.outputs.SparkClusterStorageAccount;
import com.pulumi.azure.hdinsight.outputs.SparkClusterStorageAccountGen2;
import com.pulumi.core.Output;
import com.pulumi.core.annotations.Export;
import com.pulumi.core.annotations.ResourceType;
import com.pulumi.core.internal.Codegen;
import java.lang.Boolean;
import java.lang.String;
import java.util.List;
import java.util.Map;
import java.util.Optional;
import javax.annotation.Nullable;

/**
 * Manages a HDInsight Spark Cluster.
 * 
 * ## Example Usage
 * ```java
 * package generated_program;
 * 
 * import com.pulumi.Context;
 * import com.pulumi.Pulumi;
 * import com.pulumi.core.Output;
 * import com.pulumi.azure.core.ResourceGroup;
 * import com.pulumi.azure.core.ResourceGroupArgs;
 * import com.pulumi.azure.storage.Account;
 * import com.pulumi.azure.storage.AccountArgs;
 * import com.pulumi.azure.storage.Container;
 * import com.pulumi.azure.storage.ContainerArgs;
 * import com.pulumi.azure.hdinsight.SparkCluster;
 * import com.pulumi.azure.hdinsight.SparkClusterArgs;
 * import com.pulumi.azure.hdinsight.inputs.SparkClusterComponentVersionArgs;
 * import com.pulumi.azure.hdinsight.inputs.SparkClusterGatewayArgs;
 * import com.pulumi.azure.hdinsight.inputs.SparkClusterStorageAccountArgs;
 * import com.pulumi.azure.hdinsight.inputs.SparkClusterRolesArgs;
 * import com.pulumi.azure.hdinsight.inputs.SparkClusterRolesHeadNodeArgs;
 * import com.pulumi.azure.hdinsight.inputs.SparkClusterRolesWorkerNodeArgs;
 * import com.pulumi.azure.hdinsight.inputs.SparkClusterRolesZookeeperNodeArgs;
 * import java.util.List;
 * import java.util.ArrayList;
 * import java.util.Map;
 * import java.io.File;
 * import java.nio.file.Files;
 * import java.nio.file.Paths;
 * 
 * public class App {
 *     public static void main(String[] args) {
 *         Pulumi.run(App::stack);
 *     }
 * 
 *     public static void stack(Context ctx) {
 *         var exampleResourceGroup = new ResourceGroup(&#34;exampleResourceGroup&#34;, ResourceGroupArgs.builder()        
 *             .location(&#34;West Europe&#34;)
 *             .build());
 * 
 *         var exampleAccount = new Account(&#34;exampleAccount&#34;, AccountArgs.builder()        
 *             .resourceGroupName(exampleResourceGroup.name())
 *             .location(exampleResourceGroup.location())
 *             .accountTier(&#34;Standard&#34;)
 *             .accountReplicationType(&#34;LRS&#34;)
 *             .build());
 * 
 *         var exampleContainer = new Container(&#34;exampleContainer&#34;, ContainerArgs.builder()        
 *             .storageAccountName(exampleAccount.name())
 *             .containerAccessType(&#34;private&#34;)
 *             .build());
 * 
 *         var exampleSparkCluster = new SparkCluster(&#34;exampleSparkCluster&#34;, SparkClusterArgs.builder()        
 *             .resourceGroupName(exampleResourceGroup.name())
 *             .location(exampleResourceGroup.location())
 *             .clusterVersion(&#34;3.6&#34;)
 *             .tier(&#34;Standard&#34;)
 *             .componentVersion(SparkClusterComponentVersionArgs.builder()
 *                 .spark(&#34;2.3&#34;)
 *                 .build())
 *             .gateway(SparkClusterGatewayArgs.builder()
 *                 .username(&#34;acctestusrgw&#34;)
 *                 .password(&#34;Password123!&#34;)
 *                 .build())
 *             .storageAccounts(SparkClusterStorageAccountArgs.builder()
 *                 .storageContainerId(exampleContainer.id())
 *                 .storageAccountKey(exampleAccount.primaryAccessKey())
 *                 .isDefault(true)
 *                 .build())
 *             .roles(SparkClusterRolesArgs.builder()
 *                 .headNode(SparkClusterRolesHeadNodeArgs.builder()
 *                     .vmSize(&#34;Standard_A3&#34;)
 *                     .username(&#34;acctestusrvm&#34;)
 *                     .password(&#34;AccTestvdSC4daf986!&#34;)
 *                     .build())
 *                 .workerNode(SparkClusterRolesWorkerNodeArgs.builder()
 *                     .vmSize(&#34;Standard_A3&#34;)
 *                     .username(&#34;acctestusrvm&#34;)
 *                     .password(&#34;AccTestvdSC4daf986!&#34;)
 *                     .targetInstanceCount(3)
 *                     .build())
 *                 .zookeeperNode(SparkClusterRolesZookeeperNodeArgs.builder()
 *                     .vmSize(&#34;Medium&#34;)
 *                     .username(&#34;acctestusrvm&#34;)
 *                     .password(&#34;AccTestvdSC4daf986!&#34;)
 *                     .build())
 *                 .build())
 *             .build());
 * 
 *     }
 * }
 * ```
 * 
 * ## Import
 * 
 * HDInsight Spark Clusters can be imported using the `resource id`, e.g.
 * 
 * ```sh
 *  $ pulumi import azure:hdinsight/sparkCluster:SparkCluster example /subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/mygroup1/providers/Microsoft.HDInsight/clusters/cluster1
 * ```
 * 
 */
@ResourceType(type="azure:hdinsight/sparkCluster:SparkCluster")
public class SparkCluster extends com.pulumi.resources.CustomResource {
    /**
     * Specifies the Version of HDInsights which should be used for this Cluster. Changing this forces a new resource to be created.
     * 
     */
    @Export(name="clusterVersion", type=String.class, parameters={})
    private Output<String> clusterVersion;

    /**
     * @return Specifies the Version of HDInsights which should be used for this Cluster. Changing this forces a new resource to be created.
     * 
     */
    public Output<String> clusterVersion() {
        return this.clusterVersion;
    }
    /**
     * A `component_version` block as defined below.
     * 
     */
    @Export(name="componentVersion", type=SparkClusterComponentVersion.class, parameters={})
    private Output<SparkClusterComponentVersion> componentVersion;

    /**
     * @return A `component_version` block as defined below.
     * 
     */
    public Output<SparkClusterComponentVersion> componentVersion() {
        return this.componentVersion;
    }
    /**
     * Whether encryption in transit is enabled for this Cluster. Changing this forces a new resource to be created.
     * 
     */
    @Export(name="encryptionInTransitEnabled", type=Boolean.class, parameters={})
    private Output<Boolean> encryptionInTransitEnabled;

    /**
     * @return Whether encryption in transit is enabled for this Cluster. Changing this forces a new resource to be created.
     * 
     */
    public Output<Boolean> encryptionInTransitEnabled() {
        return this.encryptionInTransitEnabled;
    }
    /**
     * A `gateway` block as defined below.
     * 
     */
    @Export(name="gateway", type=SparkClusterGateway.class, parameters={})
    private Output<SparkClusterGateway> gateway;

    /**
     * @return A `gateway` block as defined below.
     * 
     */
    public Output<SparkClusterGateway> gateway() {
        return this.gateway;
    }
    /**
     * The HTTPS Connectivity Endpoint for this HDInsight Spark Cluster.
     * 
     */
    @Export(name="httpsEndpoint", type=String.class, parameters={})
    private Output<String> httpsEndpoint;

    /**
     * @return The HTTPS Connectivity Endpoint for this HDInsight Spark Cluster.
     * 
     */
    public Output<String> httpsEndpoint() {
        return this.httpsEndpoint;
    }
    /**
     * Specifies the Azure Region which this HDInsight Spark Cluster should exist. Changing this forces a new resource to be created.
     * 
     */
    @Export(name="location", type=String.class, parameters={})
    private Output<String> location;

    /**
     * @return Specifies the Azure Region which this HDInsight Spark Cluster should exist. Changing this forces a new resource to be created.
     * 
     */
    public Output<String> location() {
        return this.location;
    }
    /**
     * A `metastores` block as defined below.
     * 
     */
    @Export(name="metastores", type=SparkClusterMetastores.class, parameters={})
    private Output</* @Nullable */ SparkClusterMetastores> metastores;

    /**
     * @return A `metastores` block as defined below.
     * 
     */
    public Output<Optional<SparkClusterMetastores>> metastores() {
        return Codegen.optional(this.metastores);
    }
    /**
     * A `monitor` block as defined below.
     * 
     */
    @Export(name="monitor", type=SparkClusterMonitor.class, parameters={})
    private Output</* @Nullable */ SparkClusterMonitor> monitor;

    /**
     * @return A `monitor` block as defined below.
     * 
     */
    public Output<Optional<SparkClusterMonitor>> monitor() {
        return Codegen.optional(this.monitor);
    }
    /**
     * Specifies the name for this HDInsight Spark Cluster. Changing this forces a new resource to be created.
     * 
     */
    @Export(name="name", type=String.class, parameters={})
    private Output<String> name;

    /**
     * @return Specifies the name for this HDInsight Spark Cluster. Changing this forces a new resource to be created.
     * 
     */
    public Output<String> name() {
        return this.name;
    }
    /**
     * A `network` block as defined below.
     * 
     */
    @Export(name="network", type=SparkClusterNetwork.class, parameters={})
    private Output</* @Nullable */ SparkClusterNetwork> network;

    /**
     * @return A `network` block as defined below.
     * 
     */
    public Output<Optional<SparkClusterNetwork>> network() {
        return Codegen.optional(this.network);
    }
    /**
     * Specifies the name of the Resource Group in which this HDInsight Spark Cluster should exist. Changing this forces a new resource to be created.
     * 
     */
    @Export(name="resourceGroupName", type=String.class, parameters={})
    private Output<String> resourceGroupName;

    /**
     * @return Specifies the name of the Resource Group in which this HDInsight Spark Cluster should exist. Changing this forces a new resource to be created.
     * 
     */
    public Output<String> resourceGroupName() {
        return this.resourceGroupName;
    }
    /**
     * A `roles` block as defined below.
     * 
     */
    @Export(name="roles", type=SparkClusterRoles.class, parameters={})
    private Output<SparkClusterRoles> roles;

    /**
     * @return A `roles` block as defined below.
     * 
     */
    public Output<SparkClusterRoles> roles() {
        return this.roles;
    }
    /**
     * A `security_profile` block as defined below.
     * 
     */
    @Export(name="securityProfile", type=SparkClusterSecurityProfile.class, parameters={})
    private Output</* @Nullable */ SparkClusterSecurityProfile> securityProfile;

    /**
     * @return A `security_profile` block as defined below.
     * 
     */
    public Output<Optional<SparkClusterSecurityProfile>> securityProfile() {
        return Codegen.optional(this.securityProfile);
    }
    /**
     * The SSH Connectivity Endpoint for this HDInsight Spark Cluster.
     * 
     */
    @Export(name="sshEndpoint", type=String.class, parameters={})
    private Output<String> sshEndpoint;

    /**
     * @return The SSH Connectivity Endpoint for this HDInsight Spark Cluster.
     * 
     */
    public Output<String> sshEndpoint() {
        return this.sshEndpoint;
    }
    /**
     * A `storage_account_gen2` block as defined below.
     * 
     */
    @Export(name="storageAccountGen2", type=SparkClusterStorageAccountGen2.class, parameters={})
    private Output</* @Nullable */ SparkClusterStorageAccountGen2> storageAccountGen2;

    /**
     * @return A `storage_account_gen2` block as defined below.
     * 
     */
    public Output<Optional<SparkClusterStorageAccountGen2>> storageAccountGen2() {
        return Codegen.optional(this.storageAccountGen2);
    }
    /**
     * One or more `storage_account` block as defined below.
     * 
     */
    @Export(name="storageAccounts", type=List.class, parameters={SparkClusterStorageAccount.class})
    private Output</* @Nullable */ List<SparkClusterStorageAccount>> storageAccounts;

    /**
     * @return One or more `storage_account` block as defined below.
     * 
     */
    public Output<Optional<List<SparkClusterStorageAccount>>> storageAccounts() {
        return Codegen.optional(this.storageAccounts);
    }
    /**
     * A map of Tags which should be assigned to this HDInsight Spark Cluster.
     * 
     */
    @Export(name="tags", type=Map.class, parameters={String.class, String.class})
    private Output</* @Nullable */ Map<String,String>> tags;

    /**
     * @return A map of Tags which should be assigned to this HDInsight Spark Cluster.
     * 
     */
    public Output<Optional<Map<String,String>>> tags() {
        return Codegen.optional(this.tags);
    }
    /**
     * Specifies the Tier which should be used for this HDInsight Spark Cluster. Possible values are `Standard` or `Premium`. Changing this forces a new resource to be created.
     * 
     */
    @Export(name="tier", type=String.class, parameters={})
    private Output<String> tier;

    /**
     * @return Specifies the Tier which should be used for this HDInsight Spark Cluster. Possible values are `Standard` or `Premium`. Changing this forces a new resource to be created.
     * 
     */
    public Output<String> tier() {
        return this.tier;
    }
    @Export(name="tlsMinVersion", type=String.class, parameters={})
    private Output</* @Nullable */ String> tlsMinVersion;

    public Output<Optional<String>> tlsMinVersion() {
        return Codegen.optional(this.tlsMinVersion);
    }

    /**
     *
     * @param name The _unique_ name of the resulting resource.
     */
    public SparkCluster(String name) {
        this(name, SparkClusterArgs.Empty);
    }
    /**
     *
     * @param name The _unique_ name of the resulting resource.
     * @param args The arguments to use to populate this resource's properties.
     */
    public SparkCluster(String name, SparkClusterArgs args) {
        this(name, args, null);
    }
    /**
     *
     * @param name The _unique_ name of the resulting resource.
     * @param args The arguments to use to populate this resource's properties.
     * @param options A bag of options that control this resource's behavior.
     */
    public SparkCluster(String name, SparkClusterArgs args, @Nullable com.pulumi.resources.CustomResourceOptions options) {
        super("azure:hdinsight/sparkCluster:SparkCluster", name, args == null ? SparkClusterArgs.Empty : args, makeResourceOptions(options, Codegen.empty()));
    }

    private SparkCluster(String name, Output<String> id, @Nullable SparkClusterState state, @Nullable com.pulumi.resources.CustomResourceOptions options) {
        super("azure:hdinsight/sparkCluster:SparkCluster", name, state, makeResourceOptions(options, id));
    }

    private static com.pulumi.resources.CustomResourceOptions makeResourceOptions(@Nullable com.pulumi.resources.CustomResourceOptions options, @Nullable Output<String> id) {
        var defaultOptions = com.pulumi.resources.CustomResourceOptions.builder()
            .version(Utilities.getVersion())
            .build();
        return com.pulumi.resources.CustomResourceOptions.merge(defaultOptions, options, id);
    }

    /**
     * Get an existing Host resource's state with the given name, ID, and optional extra
     * properties used to qualify the lookup.
     *
     * @param name The _unique_ name of the resulting resource.
     * @param id The _unique_ provider ID of the resource to lookup.
     * @param state
     * @param options Optional settings to control the behavior of the CustomResource.
     */
    public static SparkCluster get(String name, Output<String> id, @Nullable SparkClusterState state, @Nullable com.pulumi.resources.CustomResourceOptions options) {
        return new SparkCluster(name, id, state, options);
    }
}
