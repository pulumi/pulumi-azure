// *** WARNING: this file was generated by pulumi-java-gen. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

package com.pulumi.azure.media.outputs;

import com.pulumi.core.annotations.CustomType;
import java.lang.String;
import java.util.Map;
import java.util.Objects;
import java.util.Optional;
import javax.annotation.Nullable;

@CustomType
public final class TransformOutputFaceDetectorPreset {
    /**
     * @return Possible values are `SourceResolution` or `StandardDefinition`. Specifies the maximum resolution at which your video is analyzed. which will keep the input video at its original resolution when analyzed. Using `StandardDefinition` will resize input videos to standard definition while preserving the appropriate aspect ratio. It will only resize if the video is of higher resolution. For example, a 1920x1080 input would be scaled to 640x360 before processing. Switching to `StandardDefinition` will reduce the time it takes to process high resolution video. It may also reduce the cost of using this component (see &lt;https://azure.microsoft.com/en-us/pricing/details/media-services/#analytics&gt; for details). However, faces that end up being too small in the resized video may not be detected. Default to `SourceResolution`.
     * 
     */
    private @Nullable String analysisResolution;
    /**
     * @return Specifies the type of blur to apply to faces in the output video. Possible values are `Black`, `Box`, `High`, `Low`,and `Med`.
     * 
     */
    private @Nullable String blurType;
    /**
     * @return Dictionary containing key value pairs for parameters not exposed in the preset itself.
     * 
     */
    private @Nullable Map<String,String> experimentalOptions;
    /**
     * @return This mode provides the ability to choose between the following settings: 1) `Analyze` - For detection only. This mode generates a metadata JSON file marking appearances of faces throughout the video. Where possible, appearances of the same person are assigned the same ID. 2) `Combined` - Additionally redacts(blurs) detected faces. 3) `Redact` - This enables a 2-pass process, allowing for selective redaction of a subset of detected faces. It takes in the metadata file from a prior analyze pass, along with the source video, and a user-selected subset of IDs that require redaction. Default to `Analyze`.
     * 
     */
    private @Nullable String faceRedactorMode;

    private TransformOutputFaceDetectorPreset() {}
    /**
     * @return Possible values are `SourceResolution` or `StandardDefinition`. Specifies the maximum resolution at which your video is analyzed. which will keep the input video at its original resolution when analyzed. Using `StandardDefinition` will resize input videos to standard definition while preserving the appropriate aspect ratio. It will only resize if the video is of higher resolution. For example, a 1920x1080 input would be scaled to 640x360 before processing. Switching to `StandardDefinition` will reduce the time it takes to process high resolution video. It may also reduce the cost of using this component (see &lt;https://azure.microsoft.com/en-us/pricing/details/media-services/#analytics&gt; for details). However, faces that end up being too small in the resized video may not be detected. Default to `SourceResolution`.
     * 
     */
    public Optional<String> analysisResolution() {
        return Optional.ofNullable(this.analysisResolution);
    }
    /**
     * @return Specifies the type of blur to apply to faces in the output video. Possible values are `Black`, `Box`, `High`, `Low`,and `Med`.
     * 
     */
    public Optional<String> blurType() {
        return Optional.ofNullable(this.blurType);
    }
    /**
     * @return Dictionary containing key value pairs for parameters not exposed in the preset itself.
     * 
     */
    public Map<String,String> experimentalOptions() {
        return this.experimentalOptions == null ? Map.of() : this.experimentalOptions;
    }
    /**
     * @return This mode provides the ability to choose between the following settings: 1) `Analyze` - For detection only. This mode generates a metadata JSON file marking appearances of faces throughout the video. Where possible, appearances of the same person are assigned the same ID. 2) `Combined` - Additionally redacts(blurs) detected faces. 3) `Redact` - This enables a 2-pass process, allowing for selective redaction of a subset of detected faces. It takes in the metadata file from a prior analyze pass, along with the source video, and a user-selected subset of IDs that require redaction. Default to `Analyze`.
     * 
     */
    public Optional<String> faceRedactorMode() {
        return Optional.ofNullable(this.faceRedactorMode);
    }

    public static Builder builder() {
        return new Builder();
    }

    public static Builder builder(TransformOutputFaceDetectorPreset defaults) {
        return new Builder(defaults);
    }
    @CustomType.Builder
    public static final class Builder {
        private @Nullable String analysisResolution;
        private @Nullable String blurType;
        private @Nullable Map<String,String> experimentalOptions;
        private @Nullable String faceRedactorMode;
        public Builder() {}
        public Builder(TransformOutputFaceDetectorPreset defaults) {
    	      Objects.requireNonNull(defaults);
    	      this.analysisResolution = defaults.analysisResolution;
    	      this.blurType = defaults.blurType;
    	      this.experimentalOptions = defaults.experimentalOptions;
    	      this.faceRedactorMode = defaults.faceRedactorMode;
        }

        @CustomType.Setter
        public Builder analysisResolution(@Nullable String analysisResolution) {

            this.analysisResolution = analysisResolution;
            return this;
        }
        @CustomType.Setter
        public Builder blurType(@Nullable String blurType) {

            this.blurType = blurType;
            return this;
        }
        @CustomType.Setter
        public Builder experimentalOptions(@Nullable Map<String,String> experimentalOptions) {

            this.experimentalOptions = experimentalOptions;
            return this;
        }
        @CustomType.Setter
        public Builder faceRedactorMode(@Nullable String faceRedactorMode) {

            this.faceRedactorMode = faceRedactorMode;
            return this;
        }
        public TransformOutputFaceDetectorPreset build() {
            final var _resultValue = new TransformOutputFaceDetectorPreset();
            _resultValue.analysisResolution = analysisResolution;
            _resultValue.blurType = blurType;
            _resultValue.experimentalOptions = experimentalOptions;
            _resultValue.faceRedactorMode = faceRedactorMode;
            return _resultValue;
        }
    }
}
